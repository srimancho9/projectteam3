{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wMxQ_dBOMZrV",
        "outputId": "06523eb8-08d6-4092-de38-7eca2239a771"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/149.4 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.4/149.4 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.6/57.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.0/61.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m191.0/191.0 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m147.9/147.9 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.9/4.9 MB\u001b[0m \u001b[31m115.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m434.9/434.9 kB\u001b[0m \u001b[31m30.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.4/78.4 kB\u001b[0m \u001b[31m6.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.5/62.5 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.0/18.0 MB\u001b[0m \u001b[31m101.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.9/12.9 MB\u001b[0m \u001b[31m121.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.7/8.7 MB\u001b[0m \u001b[31m112.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.3/8.3 MB\u001b[0m \u001b[31m89.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.6/5.6 MB\u001b[0m \u001b[31m111.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.0/27.0 MB\u001b[0m \u001b[31m20.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m383.7/383.7 kB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m70.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.6/94.6 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.0/89.0 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m75.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m397.1/397.1 kB\u001b[0m \u001b[31m26.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m104.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.9/6.9 MB\u001b[0m \u001b[31m119.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.9/82.9 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.8/311.8 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "google-colab 1.0.0 requires requests==2.32.4, but you have requests 2.32.3 which is incompatible.\n",
            "jaxlib 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "jax 0.7.2 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "mcp 1.18.0 requires pydantic<3.0.0,>=2.11.0, but you have pydantic 2.9.2 which is incompatible.\n",
            "mcp 1.18.0 requires uvicorn>=0.31.1; sys_platform != \"emscripten\", but you have uvicorn 0.30.6 which is incompatible.\n",
            "google-adk 1.16.0 requires requests<3.0.0,>=2.32.4, but you have requests 2.32.3 which is incompatible.\n",
            "google-adk 1.16.0 requires starlette<1.0.0,>=0.46.2, but you have starlette 0.38.6 which is incompatible.\n",
            "google-adk 1.16.0 requires uvicorn<1.0.0,>=0.34.0, but you have uvicorn 0.30.6 which is incompatible.\n",
            "google-adk 1.16.0 requires watchdog<7.0.0,>=6.0.0, but you have watchdog 4.0.2 which is incompatible.\n",
            "opencv-contrib-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "umap-learn 0.5.9.post2 requires scikit-learn>=1.6, but you have scikit-learn 1.5.2 which is incompatible.\n",
            "pytensor 2.35.1 requires numpy>=2.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langchain-text-splitters 0.3.11 requires langchain-core<2.0.0,>=0.3.75, but you have langchain-core 0.2.43 which is incompatible.\n",
            "opencv-python 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "dataproc-spark-connect 0.8.3 requires tqdm>=4.67, but you have tqdm 4.66.5 which is incompatible.\n",
            "gradio 5.49.1 requires fastapi<1.0,>=0.115.2, but you have fastapi 0.115.0 which is incompatible.\n",
            "gradio 5.49.1 requires starlette<1.0,>=0.40.0, but you have starlette 0.38.6 which is incompatible.\n",
            "opencv-python-headless 4.12.0.88 requires numpy<2.3.0,>=2; python_version >= \"3.9\", but you have numpy 1.26.4 which is incompatible.\n",
            "thinc 8.3.6 requires numpy<3.0.0,>=2.0.0, but you have numpy 1.26.4 which is incompatible.\n",
            "langchain 0.3.27 requires langchain-core<1.0.0,>=0.3.72, but you have langchain-core 0.2.43 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.8/43.8 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.2/2.2 MB\u001b[0m \u001b[31m77.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.1/9.1 MB\u001b[0m \u001b[31m124.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m302.4/302.4 kB\u001b[0m \u001b[31m23.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m63.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m199.1/199.1 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m92.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "# @title Install dependencies (pinned for Colab stability; GPU recommended for SD)\n",
        "!pip -q install \\\n",
        "  praw==7.7.1 requests==2.32.3 beautifulsoup4==4.12.3 lxml==5.3.0 \\\n",
        "  python-dotenv==1.0.1 pydantic==2.9.2 tqdm==4.66.5 loguru==0.7.2 \\\n",
        "  numpy==1.26.4 scikit-learn==1.5.2 streamlit==1.38.0 pyngrok==7.2.3 \\\n",
        "  nest-asyncio==1.6.0 matplotlib==3.9.2 pdfminer.six==20240706 faiss-cpu==1.8.0.post1 \\\n",
        "  openai==1.51.2 networkx==3.3 fastapi==0.115.0 uvicorn==0.30.6 \\\n",
        "  langgraph==0.1.5\n",
        "\n",
        "# Optional: Stable Diffusion stack (GPU highly recommended)\n",
        "!pip -q install torch --extra-index-url https://download.pytorch.org/whl/cu121\n",
        "!pip -q install diffusers==0.29.0 transformers==4.41.0 accelerate==0.30.0 safetensors==0.4.2 peft==0.10.0\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Load .env (if present) and set optional fallbacks\n",
        "import os\n",
        "from pathlib import Path\n",
        "\n",
        "# Load .env if available\n",
        "try:\n",
        "    from dotenv import load_dotenv\n",
        "    _ = load_dotenv()\n",
        "except Exception:\n",
        "    pass\n",
        "\n",
        "# Optional fallback secrets for quick demo (leave blank to rely on .env)\n",
        "OPTIONAL_SECRETS = {\n",
        "    \"OPENAI_API_KEY\": \"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\",\n",
        "    \"UNPAYWALL_EMAIL\": \"jackryan76388@gmail.com\",\n",
        "    \"REDDIT_CLIENT_ID\": \"GVVuq2kgFJHHq3bFU_aC6A\",\n",
        "    \"REDDIT_CLIENT_SECRET\": \"48KIcfWC9wkRaBwYOJwnIC-mBz3X9w\",\n",
        "    \"REDDIT_USER_AGENT\": \"ReliScoreCancerBot/0.1 by u/Normal-Platform9498\",\n",
        "    \"REDDIT_USERNAME\": \"Normal-Platform9498\",\n",
        "    \"REDDIT_PASSWORD\": \"Jackryan763\",\n",
        "    \"HTTP_TIMEOUT\": \"15\",\n",
        "    \"NGROK_AUTHTOKEN\": \"342JRxQluyUnlpNgbRWrTndqGXp_4pn7QWU8YyUsrpkGT6LV3\",\n",
        "}\n",
        "for k, v in OPTIONAL_SECRETS.items():\n",
        "    if v and not os.environ.get(k):\n",
        "        os.environ[k] = v\n"
      ],
      "metadata": {
        "id": "rCq9J-QlMbG1"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Write ALL core ReliScore files (original + safe extensions)\n",
        "import textwrap\n",
        "from pathlib import Path\n",
        "\n",
        "PROJECT_ROOT = Path.cwd()\n",
        "SRC = PROJECT_ROOT / \"src\" / \"reli_core\"\n",
        "PKG_DIRS = [\n",
        "    SRC, SRC/\"nlp\", SRC/\"extract\", SRC/\"aggregate\", SRC/\"reasoner\",\n",
        "    SRC/\"writer\", SRC/\"sources\", SRC/\"assets\", SRC/\"nlg\",\n",
        "    SRC/\"graph\", SRC/\"multihop\", SRC/\"diffusion\", SRC/\"agent\", SRC/\"api\"\n",
        "]\n",
        "for d in PKG_DIRS:\n",
        "    d.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def w(rel_path: str, content: str):\n",
        "    p = PROJECT_ROOT / rel_path\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "    p.write_text(textwrap.dedent(content).strip() + \"\\n\", encoding=\"utf-8\")\n",
        "    return p\n",
        "\n",
        "# ---------- __init__ ----------\n",
        "w(\"src/reli_core/__init__.py\", \"\"\"\n",
        "from pathlib import Path\n",
        "__all__ = [\"version\", \"PACKAGE_ROOT\"]\n",
        "\n",
        "def version() -> str:\n",
        "    return \"ReliScore v0.1.0\"\n",
        "\n",
        "try:\n",
        "    PACKAGE_ROOT = Path(__file__).resolve().parent\n",
        "except NameError:\n",
        "    PACKAGE_ROOT = Path.cwd() / \"src\" / \"reli_core\"\n",
        "\"\"\")\n",
        "\n",
        "# ---------- utils / cache ----------\n",
        "w(\"src/reli_core/utils.py\", \"\"\"\n",
        "import os, time, json, hashlib, re\n",
        "from pathlib import Path\n",
        "from typing import Any, Dict, Optional, Tuple\n",
        "import requests\n",
        "from loguru import logger\n",
        "\n",
        "HTTP_TIMEOUT = int(os.environ.get(\"HTTP_TIMEOUT\", \"15\"))\n",
        "DATA_DIR = Path.cwd() / \"data_cache\"\n",
        "DATA_DIR.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "def sha1(s: str) -> str:\n",
        "    return hashlib.sha1(s.encode(\"utf-8\")).hexdigest()\n",
        "\n",
        "def cache_path(name: str) -> Path:\n",
        "    return DATA_DIR / name\n",
        "\n",
        "def save_json(path: Path, obj: Any):\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    path.write_text(json.dumps(obj, indent=2, ensure_ascii=False), encoding=\"utf-8\")\n",
        "\n",
        "def load_json(path: Path) -> Optional[Any]:\n",
        "    if path.exists():\n",
        "        return json.loads(path.read_text(encoding=\"utf-8\"))\n",
        "    return None\n",
        "\n",
        "def get(url: str, params: Optional[Dict[str, Any]] = None, headers: Optional[Dict[str, str]] = None) -> Tuple[Optional[requests.Response], Optional[str]]:\n",
        "    try:\n",
        "        res = requests.get(url, params=params, headers=headers, timeout=HTTP_TIMEOUT)\n",
        "        if res.status_code == 200:\n",
        "            return res, None\n",
        "        return None, f\"HTTP {res.status_code} for {url}\"\n",
        "    except Exception as e:\n",
        "        return None, str(e)\n",
        "\n",
        "def redact_email(text: str) -> str:\n",
        "    return re.sub(r\"[A-Za-z0-9._%+-]+@[A-Za-z0-9.-]+\\\\.[A-Za-z]{2,}\", \"[redacted-email]\", text or \"\")\n",
        "\n",
        "def dedupe_list(items):\n",
        "    seen = set()\n",
        "    out = []\n",
        "    for x in items:\n",
        "        try:\n",
        "            k = json.dumps(x, sort_keys=True, default=str)\n",
        "        except Exception:\n",
        "            k = str(x)\n",
        "        if k not in seen:\n",
        "            seen.add(k)\n",
        "            out.append(x)\n",
        "    return out\n",
        "\n",
        "def safe_int(x, default=None):\n",
        "    try:\n",
        "        return int(x)\n",
        "    except:\n",
        "        return default\n",
        "\n",
        "def now_ts() -> int:\n",
        "    return int(time.time())\n",
        "\n",
        "def log_idempotent(path: Path, key: str) -> bool:\n",
        "    path.parent.mkdir(parents=True, exist_ok=True)\n",
        "    if not path.exists():\n",
        "        path.write_text(\"\", encoding=\"utf-8\")\n",
        "    existing = set(line.strip() for line in path.read_text(encoding=\"utf-8\").splitlines() if line.strip())\n",
        "    if key in existing:\n",
        "        return False\n",
        "    with path.open(\"a\", encoding=\"utf-8\") as f:\n",
        "        f.write(key + \"\\\\n\")\n",
        "    return True\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/cache.py\", \"\"\"\n",
        "from typing import Any\n",
        "from .utils import save_json, load_json, sha1, cache_path\n",
        "\n",
        "def get_or_set(name: str, builder) -> Any:\n",
        "    p = cache_path(name)\n",
        "    obj = load_json(p)\n",
        "    if obj is not None:\n",
        "        return obj\n",
        "    obj = builder()\n",
        "    save_json(p, obj)\n",
        "    return obj\n",
        "\n",
        "def memoize_json(key: str, fn, *args, **kwargs) -> Any:\n",
        "    h = sha1(key)\n",
        "    p = cache_path(f\"memo/{h}.json\")\n",
        "    obj = load_json(p)\n",
        "    if obj is not None:\n",
        "        return obj\n",
        "    obj = fn(*args, **kwargs)\n",
        "    save_json(p, obj)\n",
        "    return obj\n",
        "\"\"\")\n",
        "\n",
        "# ---------- safety / templates / ranking ----------\n",
        "w(\"src/reli_core/safety.py\", \"\"\"\n",
        "import re\n",
        "from typing import Dict\n",
        "ADVICE_DISCLAIMER = (\"This is not medical advice. Consult a qualified clinician for decisions about \"\n",
        "                     \"diagnosis, treatment, or prevention.\")\n",
        "\n",
        "def sanitize_claim(text: str) -> str:\n",
        "    text = (text or \"\").strip()\n",
        "    text = re.sub(r\"\\\\s+\", \" \", text)\n",
        "    return text[:1000]\n",
        "\n",
        "def safety_checks(claim: str) -> Dict[str, bool]:\n",
        "    lower = (claim or \"\").lower()\n",
        "    emerg = any(x in lower for x in [\"suicid\", \"emergency\", \"chest pain\", \"unconscious\"])\n",
        "    pregnancy = \"pregnan\" in lower\n",
        "    pedi = any(x in lower for x in [\"child\", \"infant\", \"toddler\", \"pediatric\"])\n",
        "    return {\"emergency_flag\": emerg, \"pregnancy_flag\": pregnancy, \"pediatric_flag\": pedi}\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/templates.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "\n",
        "def format_citation(item: Dict) -> str:\n",
        "    year = item.get(\"year\") or \"n.d.\"\n",
        "    src = item.get(\"source\", \"Unknown\")\n",
        "    title = (item.get(\"title\", \"Untitled\") or \"\").strip()\n",
        "    ident = item.get(\"id\", \"\")\n",
        "    return f\"[{src} {year}] {title} ({ident})\"\n",
        "\n",
        "def build_citations_markdown(study_points: List[Dict], limit: int = None) -> str:\n",
        "    items = study_points if limit is None else study_points[:max(0, limit)]\n",
        "    lines = [f\"- {format_citation(c)}\" for c in items]\n",
        "    return \"\\\\n\".join(lines) if lines else \"_No citations available._\"\n",
        "\n",
        "def build_reasons_markdown(verdict: Dict) -> str:\n",
        "    rs = (verdict or {}).get(\"reasons\") or []\n",
        "    if not rs:\n",
        "        return \"_No key reasons extracted._\"\n",
        "    return \"\\\\n\".join(f\"- {r}\" for r in rs)\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/ranking.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from datetime import datetime\n",
        "\n",
        "TIER_WEIGHT = {\n",
        "    \"guideline\": 4.0, \"systematic_review\": 3.5, \"randomized_trial\": 3.0,\n",
        "    \"cohort\": 2.0, \"case_control\": 1.5, \"case_series\": 1.0,\n",
        "    \"in_vitro\": 0.5, \"animal\": 0.5,\n",
        "}\n",
        "\n",
        "def score_item(x: Dict) -> float:\n",
        "    year = x.get(\"year\") or 0\n",
        "    try:\n",
        "        recency = max(0, datetime.now().year - int(year))\n",
        "    except:\n",
        "        recency = 10\n",
        "    tier = x.get(\"tier\", \"cohort\")\n",
        "    weight = TIER_WEIGHT.get(tier, 1.0)\n",
        "    recency_factor = max(0.2, 1.0 - recency / 20.0)\n",
        "    applicability = x.get(\"applicability\", 1.0)\n",
        "    oa_boost = 1.1 if (x.get(\"oa_url\") or \"\").strip() else 1.0\n",
        "    return weight * recency_factor * (0.5 + 0.5 * applicability) * oa_boost\n",
        "\n",
        "def rank_items(items: List[Dict]) -> List[Dict]:\n",
        "    for it in items:\n",
        "        it[\"_score\"] = score_item(it)\n",
        "    return sorted(items, key=lambda z: z.get(\"_score\", 0), reverse=True)\n",
        "\"\"\")\n",
        "\n",
        "# ---------- NLP ----------\n",
        "w(\"src/reli_core/nlp/claim_detect.py\", \"\"\"\n",
        "from typing import Dict\n",
        "INTENTS = [\"prevention\",\"treatment\",\"screening\",\"supportive_care\",\"genomic\",\"anecdote\",\"meta_news\"]\n",
        "\n",
        "def classify_intent(text: str) -> str:\n",
        "    t = (text or \"\").lower()\n",
        "    if any(k in t for k in [\"breakthrough\",\"cure\",\"new treatment\",\"news\",\"headline\",\"approval\",\"fda\",\"ema\"]):\n",
        "        return \"meta_news\"\n",
        "    if any(k in t for k in [\"prevent\",\"risk\",\"lower risk\",\"prophylaxis\"]):\n",
        "        return \"prevention\"\n",
        "    if any(k in t for k in [\"treat\",\"therapy\",\"drug\",\"dose\",\"improve\",\"chemotherapy\"]):\n",
        "        return \"treatment\"\n",
        "    if any(k in t for k in [\"screen\",\"detect early\",\"psa\",\"mammogram\"]):\n",
        "        return \"screening\"\n",
        "    if any(k in t for k in [\"nausea\",\"fatigue\",\"support\"]):\n",
        "        return \"supportive_care\"\n",
        "    if any(k in t for k in [\"mutation\",\"genomic\",\"biomarker\"]):\n",
        "        return \"genomic\"\n",
        "    if any(k in t for k in [\"i feel\",\"my uncle\",\"i tried\"]):\n",
        "        return \"anecdote\"\n",
        "    return \"treatment\"\n",
        "\n",
        "def query_terms(text: str, intent: str) -> Dict[str, str]:\n",
        "    base = text.strip().rstrip(\".\")\n",
        "    if intent == \"meta_news\":\n",
        "        return {\n",
        "            \"pubmed\": \"immunotherapy checkpoint inhibitor tumor-agnostic oncology review\",\n",
        "            \"eupmc\": \"CAR-T radioligand ADC tumor-agnostic approval review\",\n",
        "            \"crossref\": \"oncology breakthroughs FDA approval checkpoint inhibitor CAR-T ADC radiopharmaceutical review\",\n",
        "            \"preprint\": \"cancer breakthrough phase 3 site:medrxiv.org OR site:biorxiv.org\",\n",
        "            \"ctgov\": \"cancer breakthrough phase 3\",\n",
        "            \"fda\": \"oncology approval breakthrough PD-1 CAR-T ADC radioligand KRAS NTRK tumor-agnostic\",\n",
        "        }\n",
        "    return {\n",
        "        \"pubmed\": f\"{base} cancer {intent}\",\n",
        "        \"eupmc\": f\"{base} cancer {intent}\",\n",
        "        \"crossref\": f\"{base} cancer {intent}\",\n",
        "        \"preprint\": f\"{base} cancer {intent} site:biorxiv.org OR site:medrxiv.org\",\n",
        "        \"ctgov\": f\"{base} cancer {intent}\",\n",
        "    }\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/nlp/normalize.py\", \"\"\"\n",
        "import re\n",
        "def normalize_title(t: str) -> str:\n",
        "    t = re.sub(r\"\\\\s+\", \" \", (t or \"\").strip())\n",
        "    return t[:500]\n",
        "\"\"\")\n",
        "\n",
        "# ---------- extract / aggregate / reasoner ----------\n",
        "w(\"src/reli_core/extract/effects.py\", \"\"\"\n",
        "import re\n",
        "from typing import Dict, Optional\n",
        "\n",
        "EFFECT_PAT = re.compile(r\"(RR|OR|HR)\\\\s*[:=]?\\\\s*([0-9]*\\\\.?[0-9]+)\\\\s*(?:\\\\(\\\\s*95%\\\\s*CI\\\\s*[:=]?\\\\s*([0-9]*\\\\.?[0-9]+)\\\\s*[-–]\\\\s*([0-9]*\\\\.?[0-9]+)\\\\s*\\\\))?\", re.I)\n",
        "SUPPORT_PAT = re.compile(r\"\\\\b(reduced risk|lower risk|protective|inverse association)\\\\b\", re.I)\n",
        "REFUTE_PAT = re.compile(r\"\\\\b(increased risk|higher risk|positive association|no reduction|no association)\\\\b\", re.I)\n",
        "\n",
        "def extract_effects(text: str) -> Optional[Dict]:\n",
        "    if not text: return None\n",
        "    m = EFFECT_PAT.search(text)\n",
        "    if not m: return None\n",
        "    kind, val, lo, hi = m.groups()\n",
        "    return {\"metric\": kind.upper(), \"value\": float(val), \"ci_low\": float(lo) if lo else None, \"ci_high\": float(hi) if hi else None}\n",
        "\n",
        "def infer_direction(title: str, abstract: str, effect: Optional[Dict]) -> str:\n",
        "    if effect and effect.get(\"value\"):\n",
        "        if effect[\"value\"] < 1.0: return \"supports\"\n",
        "        if effect[\"value\"] > 1.0: return \"refutes\"\n",
        "    blob = \" \".join([title or \"\", abstract or \"\"])\n",
        "    if SUPPORT_PAT.search(blob) and not REFUTE_PAT.search(blob): return \"supports\"\n",
        "    if REFUTE_PAT.search(blob) and not SUPPORT_PAT.search(blob): return \"refutes\"\n",
        "    return \"unclear\"\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/aggregate/prevention.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "import math\n",
        "def pooled_effect(studies: List[Dict]) -> Dict:\n",
        "    vals = [s.get(\"effect\", {}).get(\"value\") for s in studies if s.get(\"effect\")]\n",
        "    vals = [v for v in vals if isinstance(v, (int, float))]\n",
        "    if not vals: return {\"pooled\": None, \"n\": 0}\n",
        "    log_vals = [math.log(v) for v in vals if v > 0]\n",
        "    if not log_vals: return {\"pooled\": None, \"n\": 0}\n",
        "    gmean = math.exp(sum(log_vals) / len(log_vals))\n",
        "    return {\"pooled\": gmean, \"n\": len(vals)}\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/reasoner/verdict.py\", \"\"\"\n",
        "from typing import Dict, List\n",
        "from ..ranking import rank_items\n",
        "\n",
        "def decide_verdict(items: List[Dict], intent: str) -> Dict:\n",
        "    ranked = rank_items(items)\n",
        "    topk = ranked[:10]\n",
        "    positives = sum(1 for x in topk if (x.get(\"direction\") or \"\").lower() == \"supports\")\n",
        "    negatives = sum(1 for x in topk if (x.get(\"direction\") or \"\").lower() == \"refutes\")\n",
        "    label = \"Unclear\"\n",
        "    if positives >= max(2, negatives + 1): label = \"Supported\"\n",
        "    elif negatives >= max(2, positives + 1): label = \"Contradicted\"\n",
        "    elif positives > 0 and negatives > 0: label = \"Mixed\"\n",
        "    conf = min(0.95, 0.4 + 0.05 * len(topk) + 0.1 * abs(positives - negatives))\n",
        "\n",
        "    reasons = []\n",
        "    for x in topk[:8]:\n",
        "        eff = x.get(\"effect\")\n",
        "        eff_str = \"\"\n",
        "        if isinstance(eff, dict) and eff.get(\"value\"):\n",
        "            val = eff[\"value\"]\n",
        "            ci = f\" (95% CI {eff['ci_low']}-{eff['ci_high']})\" if (eff.get(\"ci_low\") and eff.get(\"ci_high\")) else \"\"\n",
        "            eff_str = f\" — {eff['metric']} {val}{ci}\"\n",
        "        reasons.append(f\"{x.get('tier','study').title()} {x.get('year','')}: {x.get('title','')} {eff_str}\".strip())\n",
        "    return {\"label\": label, \"confidence\": round(conf, 2), \"reasons\": reasons}\n",
        "\"\"\")\n",
        "\n",
        "# ---------- nlg (LLM helper) ----------\n",
        "w(\"src/reli_core/nlg/llm_helper.py\", \"\"\"\n",
        "import os, json\n",
        "from typing import Optional, Dict\n",
        "\n",
        "def _can_use_llm() -> bool:\n",
        "    return bool(os.environ.get(\"OPENAI_API_KEY\"))\n",
        "\n",
        "def explain_with_llm(facts: Dict, model: str = \"gpt-4o-mini\") -> Optional[str]:\n",
        "    if not _can_use_llm():\n",
        "        return None\n",
        "    try:\n",
        "        from openai import OpenAI\n",
        "        client = OpenAI(api_key=os.environ[\"OPENAI_API_KEY\"])\n",
        "        system = (\"You are a cautious medical explainer. Write a short, human explanation. \"\n",
        "                  \"STRICT RULES: Only use the structured 'facts' JSON provided. Do not invent new studies or numbers. \"\n",
        "                  \"No citations inline; the app will show references separately. Be kind and clear. \"\n",
        "                  \"Order your response as four paragraphs with headings: \"\n",
        "                  \"'What this actually means', 'Where the claim goes wrong or right', 'How to think about it', 'Bottom line'.\")\n",
        "        user = (\"Claim:\\\\n\" + (facts.get(\"claim\",\"\") or \"\") + \"\\\\n\\\\n\"\n",
        "                \"Verdict:\\\\n\" + json.dumps(facts.get(\"verdict\",{}), ensure_ascii=False) + \"\\\\n\\\\n\"\n",
        "                \"Evidence facts (JSON):\\\\n\" + json.dumps(facts, ensure_ascii=False))\n",
        "        resp = client.chat.completions.create(\n",
        "            model=model, temperature=0.2,\n",
        "            messages=[{\"role\":\"system\",\"content\":system},{\"role\":\"user\",\"content\":user}],\n",
        "        )\n",
        "        return resp.choices[0].message.content.strip()\n",
        "    except Exception:\n",
        "        return None\n",
        "\"\"\")\n",
        "\n",
        "# ---------- writer (LLM-first, meta-news aware fallback) ----------\n",
        "w(\"src/reli_core/writer/lay.py\", \"\"\"\n",
        "from typing import Dict, List\n",
        "try:\n",
        "    from src.reli_core.nlg.llm_helper import explain_with_llm\n",
        "except Exception:\n",
        "    explain_with_llm = None\n",
        "\n",
        "def _fmt_effect(e):\n",
        "    if not isinstance(e, dict) or not e.get(\"value\"): return None\n",
        "    val = e[\"value\"]; ci = \"\"\n",
        "    if e.get(\"ci_low\") and e.get(\"ci_high\"):\n",
        "        ci = f\" (95% CI {e['ci_low']}-{e['ci_high']})\"\n",
        "    return f\"{e.get('metric','').upper()} {val}{ci}\"\n",
        "\n",
        "def _short_support_line(te):\n",
        "    yr = te.get(\"year\") or \"\"; ttl = (te.get(\"title\") or \"\").rstrip(\".\")\n",
        "    fx = {\"metric\":te.get(\"metric\"),\"value\":te.get(\"value\"),\"ci_low\":te.get(\"ci_low\"),\"ci_high\":te.get(\"ci_high\")}\n",
        "    eff = _fmt_effect(fx); part = f\"{yr}: {ttl}\"\n",
        "    if eff: part += f\" — {eff}\"\n",
        "    return f\"{part}.\"\n",
        "\n",
        "def _human_meta_news(facts: Dict) -> str:\n",
        "    v = facts.get(\"verdict\", {}); label = v.get(\"label\",\"Unclear\"); conf = v.get(\"confidence\",0.0)\n",
        "    cts = facts.get(\"counts\", {}); years = facts.get(\"years\", {})\n",
        "    span = f\" spanning {years['earliest']}–{years['latest']}\" if years.get(\"earliest\") and years.get(\"latest\") else \"\"\n",
        "    tops = facts.get(\"top_titles\") or []\n",
        "    bullets = [f\"- {yr}: {ttl}\" for yr, ttl in tops[:6] if ttl]\n",
        "    bullet_block = \"\\\\n\".join(bullets) if bullets else \"- We retrieved high-level items (approvals/reviews), but titles were sparse.\"\n",
        "    hop_trace = facts.get(\"hop_trace\") or []\n",
        "    hop_lines = []\n",
        "    for i, hop in enumerate(hop_trace[:3], 1):\n",
        "        ex = hop.get(\"subq\",\"\").strip()\n",
        "        ans = hop.get(\"answer\",\"\").strip()\n",
        "        hop_lines.append(f\"{i}. **{ex}** → {ans}\")\n",
        "    hop_block = \"\\\\n\".join(hop_lines)\n",
        "\n",
        "    p1 = (f\"**What this actually means**  \\\\n\"\n",
        "          f\"We looked for real, patient-impactful advances (phase 3 results, approvals, guideline shifts). \"\n",
        "          f\"We found {cts.get('total',0)} items{span}. Examples from titles:\\\\n{bullet_block}\")\n",
        "    p2 = (\"**Where the claim goes wrong or right**  \\\\n\"\n",
        "          \"Headlines often hype early lab or phase-1/2 signals that never survive phase-3 trials. \"\n",
        "          \"Real breakthroughs have regulatory approval and guideline adoption.\")\n",
        "    p3 = (\"**How to think about it**  \\\\n\"\n",
        "          \"Focus on results that reached phase 3 and approval (checkpoint inhibitors, CAR-T, radioligand therapy, ADCs, KRAS/NTRK-targeted drugs). \"\n",
        "          \"They don't cure all cancers, but for specific groups they extend survival or yield durable remissions.\")\n",
        "    p4 = f\"**Bottom line**  \\\\nVerdict: **{label}** (confidence {conf:.2f}).\"\n",
        "    if hop_block:\n",
        "        p4 += f\"\\\\n\\\\n**Reasoning hops (condensed):**\\\\n{hop_block}\"\n",
        "    return \"\\\\n\\\\n\".join([p1,p2,p3,p4])\n",
        "\n",
        "def _human_general(facts: Dict) -> str:\n",
        "    v = facts.get(\"verdict\", {}); label = v.get(\"label\",\"Unclear\"); conf = v.get(\"confidence\",0.0)\n",
        "    cts = facts.get(\"counts\", {}); years = facts.get(\"years\", {}); span = f\" spanning {years['earliest']}–{years['latest']}\" if years.get(\"earliest\") and years.get(\"latest\") else \"\"\n",
        "    avg = facts.get(\"avg_score\"); avg_txt = f\" with average quality score ≈ {avg:.2f}\" if isinstance(avg,(int,float)) else \"\"\n",
        "    pooled = facts.get(\"pooled_effect\"); pooled_txt = f\" Pooled effect ≈ {pooled:.2f} (ratio < 1 suggests lower risk).\" if isinstance(pooled,(int,float)) and pooled>0 else \"\"\n",
        "    tops = facts.get(\"top_effects\") or []\n",
        "    study_lines = []\n",
        "    for te in tops[:3]: study_lines.append(_short_support_line(te))\n",
        "    studies_txt = \" \".join(study_lines) if study_lines else \"\"\n",
        "    if not studies_txt:\n",
        "        tt = facts.get(\"top_titles\") or []\n",
        "        named = \"; \".join([f\"{y}: {t}\" for y,t in tt[:3] if t])\n",
        "        if named: studies_txt = f\"Examples: {named}.\"\n",
        "    hop_trace = facts.get(\"hop_trace\") or []\n",
        "    hop_lines = []\n",
        "    for i, hop in enumerate(hop_trace[:2], 1):\n",
        "        ex = hop.get(\"subq\",\"\").strip()\n",
        "        ans = hop.get(\"answer\",\"\").strip()\n",
        "        hop_lines.append(f\"{i}. **{ex}** → {ans}\")\n",
        "    hop_block = \"\\\\n\".join(hop_lines)\n",
        "\n",
        "    p1 = (f\"**What this actually means**  \\\\n\"\n",
        "          f\"We analyzed open-access sources and identified {cts.get('total',0)} relevant items{span}. \"\n",
        "          f\"Of these, {cts.get('supports',0)} support, {cts.get('refutes',0)} refute, and {cts.get('unclear',0)} are uncertain{avg_txt}.{pooled_txt} \"\n",
        "          f\"{(' Key examples: ' + studies_txt) if studies_txt else ''}\")\n",
        "    middle = {\n",
        "        \"Supported\": \"Higher-ranked evidence supports the claim, but magnitudes vary and do not imply certainty.\",\n",
        "        \"Contradicted\": \"Higher-ranked evidence tends to contradict the claim; reported effects point away from benefit.\",\n",
        "        \"Mixed\": \"Evidence points in both directions; design and population differences likely explain the split.\",\n",
        "        \"Unclear\": \"Current evidence is limited or inconsistent; stronger, targeted studies are needed.\"\n",
        "    }.get(label, \"Interpret cautiously.\")\n",
        "    p2 = f\"**Where the claim goes wrong or right**  \\\\n{middle}\"\n",
        "    p3 = (\"**How to think about it**  \\\\n\"\n",
        "          \"Interpret results in context: study quality, recency, consistency, and relevance to your population. \"\n",
        "          \"Be cautious with absolute language like “always” or “never.”\")\n",
        "    p4 = f\"**Bottom line**  \\\\nVerdict: **{label}** (confidence {conf:.2f}).\"\n",
        "    if hop_block: p4 += f\"\\\\n\\\\n**Reasoning hops (condensed):**\\\\n{hop_block}\"\n",
        "    return \"\\\\n\\\\n\".join([p1,p2,p3,p4])\n",
        "\n",
        "def write_explanation(claim: str, verdict: Dict, aggregates: Dict, study_points: List[Dict], intent: str, facts: Dict = None) -> str:\n",
        "    facts = facts or {}\n",
        "    if explain_with_llm is not None:\n",
        "        try:\n",
        "            llm_text = explain_with_llm(facts)\n",
        "            if llm_text: return llm_text\n",
        "        except Exception:\n",
        "            pass\n",
        "    if facts.get(\"intent\") == \"meta_news\":\n",
        "        return _human_meta_news(facts)\n",
        "    return _human_general(facts)\n",
        "\n",
        "def graph_explanations(study_points: List[Dict], verdict: Dict) -> Dict[str, Dict[str, str]]:\n",
        "    return {}\n",
        "\"\"\")\n",
        "\n",
        "# ---------- sources ----------\n",
        "w(\"src/reli_core/sources/__init__.py\", \"\"\"\n",
        "from typing import Dict\n",
        "def base_item(**kw) -> Dict:\n",
        "    d = dict(\n",
        "        id=kw.get(\"id\",\"\"), source=kw.get(\"source\",\"\"), title=kw.get(\"title\",\"Untitled\"),\n",
        "        year=kw.get(\"year\", None), tier=kw.get(\"tier\",\"cohort\"), applicability=kw.get(\"applicability\",1.0),\n",
        "        oa_url=kw.get(\"oa_url\",\"\"), pmid=kw.get(\"pmid\",\"\"), pmcid=kw.get(\"pmcid\",\"\"),\n",
        "        abstract=kw.get(\"abstract\",\"\"), direction=kw.get(\"direction\",\"unclear\"),\n",
        "        summary=kw.get(\"summary\",\"\"), effect=kw.get(\"effect\"),\n",
        "    )\n",
        "    return d\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/pubmed.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from ..utils import get\n",
        "from . import base_item\n",
        "EUTILS = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esearch.fcgi\"\n",
        "ESUMMARY = \"https://eutils.ncbi.nlm.nih.gov/entrez/eutils/esummary.fcgi\"\n",
        "\n",
        "def search_pubmed(query: str, n: int = 20) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    if not query: return items\n",
        "    res, err = get(EUTILS, params={\"db\":\"pubmed\",\"retmode\":\"json\",\"retmax\":str(n),\"term\":query})\n",
        "    if err or not res: return items\n",
        "    data = res.json()\n",
        "    ids = data.get(\"esearchresult\",{}).get(\"idlist\",[])[:n]\n",
        "    if not ids: return items\n",
        "    res2, err2 = get(ESUMMARY, params={\"db\":\"pubmed\",\"retmode\":\"json\",\"id\":\",\".join(ids)})\n",
        "    if err2 or not res2: return items\n",
        "    summ = res2.json().get(\"result\",{})\n",
        "    for pid in ids:\n",
        "        r = summ.get(pid)\n",
        "        if not r: continue\n",
        "        title = (r.get(\"title\") or \"\").strip().rstrip(\".\")\n",
        "        try: year = int((r.get(\"pubdate\",\"\") or \"\")[:4])\n",
        "        except: year = None\n",
        "        items.append(base_item(\n",
        "            id=f\"PMID:{pid}\", source=\"PubMed\", title=title, year=year, tier=\"cohort\",\n",
        "            applicability=1.0, pmid=pid, summary=r.get(\"sortfirstauthor\") or \"\", direction=\"unclear\"\n",
        "        ))\n",
        "    return items\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/europe_pmc.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from ..utils import get\n",
        "from . import base_item\n",
        "EPMC = \"https://www.ebi.ac.uk/europepmc/webservices/rest/search\"\n",
        "\n",
        "def search_eupmc(query: str, n: int = 20) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    if not query: return items\n",
        "    res, err = get(EPMC, params={\"query\":query, \"resultType\":\"core\", \"format\":\"json\", \"pageSize\":str(n)})\n",
        "    if err or not res: return items\n",
        "    docs = res.json().get(\"resultList\",{}).get(\"result\",[])\n",
        "    for d in docs[:n]:\n",
        "        pmcid = d.get(\"pmcid\",\"\"); pmid = d.get(\"pmid\",\"\"); title = (d.get(\"title\") or \"\").strip()\n",
        "        try: year = int(d.get(\"pubYear\")) if (d.get(\"pubYear\") or \"\").isdigit() else None\n",
        "        except: year = None\n",
        "        abstract = d.get(\"abstractText\",\"\") or \"\"\n",
        "        items.append(base_item(\n",
        "            id=f\"PMCID:{pmcid}\" if pmcid else (f\"PMID:{pmid}\" if pmid else d.get(\"id\",\"EPMC\")),\n",
        "            source=\"EuropePMC\", title=title, year=year, tier=\"cohort\", applicability=1.0,\n",
        "            pmid=pmid, pmcid=pmcid, oa_url=(f\"https://europepmc.org/article/pmcid/{pmcid}\" if pmcid else \"\"),\n",
        "            abstract=abstract, summary=d.get(\"journalTitle\",\"\"), direction=\"unclear\"\n",
        "        ))\n",
        "    return items\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/crossref.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from ..utils import get\n",
        "from . import base_item\n",
        "API = \"https://api.crossref.org/works\"\n",
        "\n",
        "def search_crossref(query: str, n: int = 15) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    if not query: return items\n",
        "    res, err = get(API, params={\"query\":query, \"rows\":str(n)})\n",
        "    if err or not res: return items\n",
        "    for it in res.json().get(\"message\",{}).get(\"items\",[])[:n]:\n",
        "        title = \" \".join(it.get(\"title\") or [])[:300]\n",
        "        try: year = it.get(\"issued\",{}).get(\"date-parts\",[[None]])[0][0]\n",
        "        except: year = None\n",
        "        doi = it.get(\"DOI\",\"\")\n",
        "        items.append(base_item(\n",
        "            id=f\"DOI:{doi}\" if doi else title[:24], source=\"Crossref\", title=title, year=year,\n",
        "            tier=\"cohort\", applicability=0.8, oa_url=\"\", summary=(it.get(\"container-title\") or [\"\"])[0],\n",
        "            direction=\"unclear\"\n",
        "        ))\n",
        "    return items\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/preprints.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from ..utils import get\n",
        "from . import base_item\n",
        "CR = \"https://api.crossref.org/works\"\n",
        "\n",
        "def search_preprints(query: str, n: int = 10) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    if not query: return items\n",
        "    q = f\"{query} (biorxiv OR medrxiv)\"\n",
        "    res, err = get(CR, params={\"query\":q, \"rows\":str(n)})\n",
        "    if err or not res: return items\n",
        "    for it in res.json().get(\"message\",{}).get(\"items\",[])[:n]:\n",
        "        title = \" \".join(it.get(\"title\") or [])[:300]\n",
        "        try: year = it.get(\"issued\",{}).get(\"date-parts\",[[None]])[0][0]\n",
        "        except: year = None\n",
        "        doi = it.get(\"DOI\",\"\")\n",
        "        items.append(base_item(\n",
        "            id=f\"DOI:{doi}\" if doi else title[:24], source=\"Preprint\", title=title, year=year,\n",
        "            tier=\"case_series\", applicability=0.6, oa_url=\"\", summary=\"preprint\", direction=\"unclear\"\n",
        "        ))\n",
        "    return items\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/ctgov.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from ..utils import get\n",
        "from . import base_item\n",
        "API = \"https://clinicaltrials.gov/api/v2/studies\"\n",
        "\n",
        "def search_ctgov(query: str, n: int = 10) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    if not query: return items\n",
        "    res, err = get(API, params={\"query.term\":query, \"pageSize\":str(n)})\n",
        "    if err or not res: return items\n",
        "    for st in res.json().get(\"studies\",[])[:n]:\n",
        "        ident = st.get(\"protocolSection\",{}).get(\"identificationModule\",{}).get(\"nctId\",\"\")\n",
        "        title = st.get(\"protocolSection\",{}).get(\"identificationModule\",{}).get(\"officialTitle\",\"\") or \\\n",
        "                st.get(\"protocolSection\",{}).get(\"identificationModule\",{}).get(\"briefTitle\",\"\")\n",
        "        items.append(base_item(\n",
        "            id=ident or title[:24], source=\"ClinicalTrials.gov\", title=title, year=None, tier=\"randomized_trial\",\n",
        "            applicability=0.7, oa_url=f\"https://clinicaltrials.gov/study/{ident}\" if ident else \"\",\n",
        "            summary=\"trial\", direction=\"unclear\"\n",
        "        ))\n",
        "    return items\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/fulltext.py\", \"\"\"\n",
        "from typing import Optional, Dict\n",
        "from ..utils import get\n",
        "import os\n",
        "UNPAYWALL = \"https://api.unpaywall.org/v2/\"\n",
        "\n",
        "def _pick_best_oa(data: dict) -> Optional[str]:\n",
        "    if not isinstance(data, dict): return None\n",
        "    best = data.get(\"best_oa_location\")\n",
        "    if isinstance(best, dict):\n",
        "        return best.get(\"url_for_pdf\") or best.get(\"url\")\n",
        "    locs = data.get(\"oa_locations\") or []\n",
        "    for loc in locs:\n",
        "        if not isinstance(loc, dict): continue\n",
        "        url = loc.get(\"url_for_pdf\") or loc.get(\"url\")\n",
        "        if url: return url\n",
        "    return None\n",
        "\n",
        "def best_oa_url(doi: str) -> Optional[str]:\n",
        "    email = os.environ.get(\"UNPAYWALL_EMAIL\",\"\").strip()\n",
        "    if not doi or not email: return None\n",
        "    res, err = get(f\"{UNPAYWALL}{doi}\", params={\"email\": email})\n",
        "    if err or not res: return None\n",
        "    try: data = res.json() or {}\n",
        "    except Exception: return None\n",
        "    return _pick_best_oa(data)\n",
        "\n",
        "def enrich_oa(item: Dict) -> Dict:\n",
        "    try:\n",
        "        doi = (item.get(\"id\",\"\").split(\"DOI:\",1)[-1]) if \"DOI:\" in item.get(\"id\",\"\") else \"\"\n",
        "        if not item.get(\"oa_url\") and doi:\n",
        "            url = best_oa_url(doi)\n",
        "            if url: item[\"oa_url\"] = url\n",
        "        return item\n",
        "    except Exception:\n",
        "        return item\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/agency.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from . import base_item\n",
        "SITEMAPS = {\"WHO\": \"https://www.who.int/sitemap.xml\",\"CDC\": \"https://www.cdc.gov/sitemap.xml\",\"NICE\": \"https://www.nice.org.uk/sitemap.xml\"}\n",
        "\n",
        "def harvest_agencies(keyword: str, n: int = 10) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    for k in [\"WHO\",\"CDC\",\"NICE\"]:\n",
        "        items.append(base_item(\n",
        "            id=f\"{k}:{keyword}\", source=k, title=f\"{k} guidance related to {keyword}\", year=None, tier=\"guideline\",\n",
        "            applicability=1.0, oa_url=SITEMAPS[k], summary=\"agency guidance\", direction=\"unclear\"\n",
        "        ))\n",
        "    return items[:n]\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/repos.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from . import base_item\n",
        "\n",
        "def find_datasets(keyword: str, n: int = 5) -> List[Dict]:\n",
        "    repos = [\"Zenodo\", \"Dryad\", \"Figshare\", \"OSF\"]\n",
        "    out: List[Dict] = []\n",
        "    for r in repos[:n]:\n",
        "        out.append(base_item(\n",
        "            id=f\"{r}:{keyword}\", source=r, title=f\"{r} dataset for {keyword}\", year=None, tier=\"case_series\",\n",
        "            applicability=0.5, oa_url=f\"https://{r.lower()}.org\", summary=\"dataset\", direction=\"unclear\"\n",
        "        ))\n",
        "    return out\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/sources/fda.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from ..utils import get\n",
        "from . import base_item\n",
        "API = \"https://api.fda.gov/drug/drugsfda.json\"\n",
        "KEY_TERMS = [\"pembrolizumab\",\"nivolumab\",\"atezolizumab\",\"durvalumab\",\"ipilimumab\",\n",
        "             \"tisagenlecleucel\",\"axicabtagene\",\"idecabtagene\",\"ciltacabtagene\",\n",
        "             \"sotorasib\",\"adagrasib\",\"larotrectinib\",\"entrectinib\",\n",
        "             \"trastuzumab deruxtecan\",\"enhertu\",\"pluvicto\",\"lutetium\",\"psma\"]\n",
        "\n",
        "def search_fda_oncology(query: str, n: int = 25) -> List[Dict]:\n",
        "    items: List[Dict] = []\n",
        "    for term in KEY_TERMS:\n",
        "        res, err = get(API, params={\"search\": f'products.brand_name:\"{term}\"', \"limit\": str(n)})\n",
        "        if err or not res: continue\n",
        "        for r in res.json().get(\"results\", []):\n",
        "            app = r.get(\"applications\", [{}])[0]\n",
        "            prod = (r.get(\"products\") or [{}])[0]\n",
        "            title = f\"FDA approval: {prod.get('brand_name','')} ({prod.get('active_ingredients','')})\"\n",
        "            try:\n",
        "                y = (app.get(\"action_date\",\"\") or \"\")[:4]; year = int(y) if y.isdigit() else None\n",
        "            except:\n",
        "                year = None\n",
        "            items.append(base_item(\n",
        "                id=f\"FDA:{prod.get('brand_name','')}\", source=\"FDA\", title=title, year=year, tier=\"guideline\",\n",
        "                applicability=1.0, oa_url=\"https://www.fda.gov/drugs/drug-approvals-and-databases/drugsfda-data-files\",\n",
        "                summary=\"FDA approval\", direction=\"unclear\"\n",
        "            ))\n",
        "    return items\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Topic harvest ----------\n",
        "w(\"src/reli_core/topic_harvest.py\", \"\"\"\n",
        "from typing import Dict, List\n",
        "from .sources.pubmed import search_pubmed\n",
        "from .sources.europe_pmc import search_eupmc\n",
        "from .sources.crossref import search_crossref\n",
        "from .sources.preprints import search_preprints\n",
        "from .sources.ctgov import search_ctgov\n",
        "from .sources.agency import harvest_agencies\n",
        "from .sources.repos import find_datasets\n",
        "from .ranking import rank_items\n",
        "from .utils import dedupe_list\n",
        "\n",
        "def harvest_topic(keyword: str, limit: int = 50) -> Dict[str, List[Dict]]:\n",
        "    pools = []\n",
        "    pools += search_pubmed(keyword, n=20)\n",
        "    pools += search_eupmc(keyword, n=20)\n",
        "    pools += search_crossref(keyword, n=15)\n",
        "    pools += search_preprints(keyword, n=10)\n",
        "    pools += search_ctgov(keyword, n=10)\n",
        "    pools += harvest_agencies(keyword, n=5)\n",
        "    pools += find_datasets(keyword, n=5)\n",
        "    items = dedupe_list(pools)\n",
        "    ranked = rank_items(items)[:limit]\n",
        "    return {\"items\": ranked}\n",
        "\"\"\")\n",
        "print(\"✅ Core files written.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QsHGlgW1MqJE",
        "outputId": "ae84d3ef-b728-47c9-ef8b-01a337cb8d95"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Core files written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Write Graph-RAG + Multi-Hop modules (Week-6)\n",
        "from pathlib import Path\n",
        "import textwrap\n",
        "\n",
        "def w(rel_path: str, content: str):\n",
        "    p = Path(rel_path)\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "    p.write_text(textwrap.dedent(content).strip() + \"\\n\", encoding=\"utf-8\")\n",
        "    return p\n",
        "\n",
        "# ---------- Graph build ----------\n",
        "w(\"src/reli_core/graph/build_graph.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "from pathlib import Path\n",
        "import re, pickle\n",
        "import networkx as nx\n",
        "from ..utils import cache_path\n",
        "\n",
        "ENTITY_PAT = re.compile(r\"\\\\b([A-Z][a-z0-9]+(?:-[A-Z0-9]+)?)\\\\b\")\n",
        "\n",
        "def extract_entities(title: str) -> Dict[str, str]:\n",
        "    # very light heuristics: treat capitalized tokens as candidate entities\n",
        "    ents = set(ENTITY_PAT.findall(title or \"\"))\n",
        "    return {e:e for e in list(ents)[:12]}\n",
        "\n",
        "def build_entity_graph(items: List[Dict]) -> nx.Graph:\n",
        "    g = nx.Graph()\n",
        "    for it in items:\n",
        "        title = it.get(\"title\",\"\") or \"\"\n",
        "        ents = extract_entities(title)\n",
        "        paper_id = it.get(\"id\",\"paper\")\n",
        "        g.add_node(paper_id, kind=\"paper\", title=title, year=it.get(\"year\"), source=it.get(\"source\"))\n",
        "        for e in ents:\n",
        "            g.add_node(e, kind=\"entity\")\n",
        "            g.add_edge(paper_id, e, rel=\"mentions\")\n",
        "    return g\n",
        "\n",
        "def persist_graph(g, path: str = None) -> str:\n",
        "    path = path or str(cache_path(\"graphrag_graph.pkl\"))\n",
        "    with open(path, \"wb\") as f:\n",
        "        pickle.dump(g, f)\n",
        "    return path\n",
        "\n",
        "def load_graph(path: str = None):\n",
        "    path = path or str(cache_path(\"graphrag_graph.pkl\"))\n",
        "    if not Path(path).exists(): return None\n",
        "    with open(path, \"rb\") as f:\n",
        "        return pickle.load(f)\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Graph-RAG retriever ----------\n",
        "w(\"src/reli_core/graph/graphrag.py\", \"\"\"\n",
        "from typing import Dict, List\n",
        "import networkx as nx\n",
        "from .build_graph import extract_entities\n",
        "from ..ranking import rank_items\n",
        "\n",
        "def extract_seed_entities(text: str) -> Dict[str,str]:\n",
        "    return extract_entities(text)\n",
        "\n",
        "def _neighbors_k_hops(g: nx.Graph, seeds: List[str], hops: int = 2) -> Dict:\n",
        "    seen = set(seeds)\n",
        "    frontier = set(seeds)\n",
        "    for _ in range(hops):\n",
        "        next_frontier = set()\n",
        "        for node in frontier:\n",
        "            for n in g.neighbors(node):\n",
        "                if n not in seen:\n",
        "                    seen.add(n); next_frontier.add(n)\n",
        "        frontier = next_frontier\n",
        "    nodes = list(seen)\n",
        "    edges = [(u,v,g.edges[u,v].get(\"rel\",\"\")) for u in nodes for v in g.neighbors(u) if v in nodes and u < v]\n",
        "    return {\"nodes\": nodes, \"edges\": edges}\n",
        "\n",
        "def graphrag_retrieve(g: nx.Graph, query: str, corpus_items: List[Dict], k: int = 8, hops: int = 2) -> Dict:\n",
        "    if g is None or g.number_of_nodes() == 0:\n",
        "        return {\"spans\": [], \"neighborhood\": {\"nodes\":[],\"edges\":[]}}\n",
        "    seeds = list(extract_seed_entities(query).keys()) or []\n",
        "    # rank corpus by overlap with seeds (very light)\n",
        "    scored = []\n",
        "    for it in corpus_items:\n",
        "        title = (it.get(\"title\") or \"\").lower()\n",
        "        score = sum(1 for s in seeds if s.lower() in title)\n",
        "        scored.append((score, it))\n",
        "    scored.sort(key=lambda z: (z[0], z[1].get(\"_score\",0)), reverse=True)\n",
        "    top = [it for sc, it in scored[:k] if sc > 0] or [it for sc, it in scored[:k]]\n",
        "    spans = []\n",
        "    for it in top:\n",
        "        spans.append({\n",
        "            \"text\": (it.get(\"abstract\") or it.get(\"summary\") or it.get(\"title\") or \"\")[:400],\n",
        "            \"source_id\": it.get(\"id\"),\n",
        "            \"title\": it.get(\"title\"),\n",
        "            \"year\": it.get(\"year\"),\n",
        "            \"oa_url\": it.get(\"oa_url\")\n",
        "        })\n",
        "    # assemble neighborhood on seeds + top paper IDs\n",
        "    seeds2 = seeds + [t.get(\"id\") for t in top if t.get(\"id\")]\n",
        "    neighborhood = _neighbors_k_hops(g, seeds2, hops=hops)\n",
        "    return {\"spans\": spans, \"neighborhood\": neighborhood}\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Multi-Hop router + QA ----------\n",
        "w(\"src/reli_core/multihop/router.py\", \"\"\"\n",
        "def route(query: str) -> str:\n",
        "    q = (query or \"\").lower()\n",
        "    # crude conditions for multi-hop: conjunctions, sequences, explicit 'which ... and which ...'\n",
        "    if any(x in q for x in [\" which \", \" and which \", \" then \", \" first \", \" second \", \" compare \", \" vs \"]):\n",
        "        return \"multi_hop\"\n",
        "    if any(x in q for x in [\"breakthrough\",\"approval\",\"phase 3\",\"meta analysis\"]):\n",
        "        return \"multi_hop\"\n",
        "    return \"single_hop\"\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/multihop/qa.py\", \"\"\"\n",
        "from typing import Dict, List\n",
        "from ..graph.graphrag import graphrag_retrieve\n",
        "from ..graph.build_graph import build_entity_graph\n",
        "\n",
        "def _propose_subqs(query: str) -> List[str]:\n",
        "    q = (query or \"\").strip().rstrip(\"?\")\n",
        "    # ultra-light planner: split by 'and', 'then'\n",
        "    parts = []\n",
        "    for cut in [\" then \", \" and \"]:\n",
        "        if cut in q.lower():\n",
        "            parts = [p.strip() for p in q.lower().split(cut) if p.strip()]\n",
        "            break\n",
        "    if not parts: parts = [q]\n",
        "    return parts[:3]\n",
        "\n",
        "def run_multihop(g, query: str, corpus_items: List[Dict], hop_limit: int = 3, k: int = 6) -> Dict:\n",
        "    subqs = _propose_subqs(query)\n",
        "    trace = []\n",
        "    acc_entities = set()\n",
        "    all_spans = []\n",
        "    for i, subq in enumerate(subqs[:hop_limit]):\n",
        "        r = graphrag_retrieve(g, subq, corpus_items, k=k, hops=2)\n",
        "        spans = r.get(\"spans\",[])\n",
        "        all_spans.extend(spans)\n",
        "        # 'answer' here is just the best span's title/year\n",
        "        if spans:\n",
        "            best = spans[0]\n",
        "            ans = f\"{best.get('title','')[:60]} ({best.get('year','')})\"\n",
        "            cits = [f\"{s.get('title','')[:60]} ({s.get('year','')})\" for s in spans[:3]]\n",
        "        else:\n",
        "            ans, cits = \"No strong match found\", []\n",
        "        trace.append({\"subq\": subq, \"answer\": ans, \"citations\": cits, \"entities\": list(acc_entities)})\n",
        "    return {\"final_answer\": trace[-1][\"answer\"] if trace else \"\", \"hop_trace\": trace, \"graph_snippets\": all_spans, \"citations\": all_spans}\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Graph visualization (mini) ----------\n",
        "w(\"src/reli_core/viz_graph.py\", \"\"\"\n",
        "from typing import Dict\n",
        "import matplotlib.pyplot as plt\n",
        "import networkx as nx\n",
        "import io, base64\n",
        "\n",
        "def draw_neighborhood(neighborhood: Dict, out_path: str) -> str:\n",
        "    nodes = neighborhood.get(\"nodes\") or []\n",
        "    edges = neighborhood.get(\"edges\") or []\n",
        "    if not nodes:\n",
        "        fig, ax = plt.subplots(figsize=(4,2))\n",
        "        ax.text(0.5,0.5,\"No neighborhood\",ha=\"center\",va=\"center\"); ax.axis(\"off\")\n",
        "        fig.savefig(out_path, bbox_inches=\"tight\"); plt.close(fig)\n",
        "        return out_path\n",
        "    g = nx.Graph()\n",
        "    g.add_nodes_from(nodes)\n",
        "    for u,v,rel in edges:\n",
        "        g.add_edge(u,v,rel=rel)\n",
        "    pos = nx.spring_layout(g, seed=42, k=0.6)\n",
        "    fig, ax = plt.subplots(figsize=(5,4))\n",
        "    nx.draw_networkx_nodes(g, pos, node_size=300, ax=ax)\n",
        "    nx.draw_networkx_labels(g, pos, font_size=8, ax=ax)\n",
        "    nx.draw_networkx_edges(g, pos, alpha=0.6, ax=ax)\n",
        "    ax.axis(\"off\")\n",
        "    fig.savefig(out_path, bbox_inches=\"tight\")\n",
        "    plt.close(fig)\n",
        "    return out_path\n",
        "\"\"\")\n",
        "print(\"✅ Week-6 Graph-RAG + Multi-Hop modules written.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "xlIue2wOMsEZ",
        "outputId": "cf1708a1-4f0a-45ef-d189-b2858cb96b91"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Week-6 Graph-RAG + Multi-Hop modules written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Week-7 additions: config, diffusion (SD), agent, FastAPI\n",
        "from pathlib import Path\n",
        "import textwrap\n",
        "\n",
        "def w(rel_path: str, content: str):\n",
        "    p = Path(rel_path)\n",
        "    p.parent.mkdir(parents=True, exist_ok=True)\n",
        "    p.write_text(textwrap.dedent(content).strip() + \"\\n\", encoding=\"utf-8\")\n",
        "    return p\n",
        "\n",
        "# ---------- Config loader ----------\n",
        "w(\"src/reli_core/config.py\", \"\"\"\n",
        "import json, os\n",
        "from pathlib import Path\n",
        "\n",
        "DEFAULTS = {\n",
        "    \"graphrag\": {\"retriever_k\": 6, \"hops\": 2},\n",
        "    \"multihop\": {\"hop_limit\": 3},\n",
        "    \"sd\": {\"model_id\": \"runwayml/stable-diffusion-v1-5\", \"height\": 512, \"width\": 512, \"steps\": 25, \"guidance\": 7.5},\n",
        "    \"agent\": {\"max_hops\": 3, \"enable_calculator\": True, \"allow_images\": True},\n",
        "}\n",
        "\n",
        "def load_json_if_exists(p: str):\n",
        "    try:\n",
        "        fp = Path(p)\n",
        "        if fp.exists():\n",
        "            return json.loads(fp.read_text(encoding=\"utf-8\"))\n",
        "    except Exception:\n",
        "        pass\n",
        "    return {}\n",
        "\n",
        "def load_run_config():\n",
        "    cfg = DEFAULTS.copy()\n",
        "    cfg.update(load_json_if_exists(\"/mnt/data/Week7_run_config.json\"))\n",
        "    env_cfg = load_json_if_exists(\"/mnt/data/Week7-env_week7.json\")\n",
        "    if env_cfg:\n",
        "        cfg[\"env\"] = env_cfg\n",
        "    return cfg\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Diffusion (Stable Diffusion wrapper) ----------\n",
        "w(\"src/reli_core/diffusion/lora_loader.py\", \"\"\"\n",
        "from typing import Optional\n",
        "def maybe_apply_lora(pipe, lora_path: Optional[str] = None):\n",
        "    # Placeholder for LoRA application; keep no-op if none provided.\n",
        "    return pipe\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/diffusion/sd_service.py\", \"\"\"\n",
        "from typing import Optional, Dict\n",
        "import torch\n",
        "from diffusers import StableDiffusionPipeline, StableDiffusionImg2ImgPipeline, StableDiffusionInpaintPipeline\n",
        "from .lora_loader import maybe_apply_lora\n",
        "\n",
        "class SDService:\n",
        "    def __init__(self, model_id: str = \"runwayml/stable-diffusion-v1-5\", device: Optional[str] = None, lora_path: Optional[str] = None):\n",
        "        device = device or (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.txt2img = StableDiffusionPipeline.from_pretrained(model_id, torch_dtype=torch.float16 if device==\"cuda\" else torch.float32)\n",
        "        self.txt2img = self.txt2img.to(device)\n",
        "        maybe_apply_lora(self.txt2img, lora_path)\n",
        "        self.device = device\n",
        "\n",
        "    @torch.inference_mode()\n",
        "    def generate(self, prompt: str, negative_prompt: Optional[str] = None, height: int = 512, width: int = 512, steps: int = 25, guidance: float = 7.5, seed: Optional[int] = None) -> Dict:\n",
        "        if seed is not None:\n",
        "            generator = torch.Generator(device=self.device).manual_seed(int(seed))\n",
        "        else:\n",
        "            generator = None\n",
        "        out = self.txt2img(prompt=prompt, negative_prompt=negative_prompt, height=height, width=width, num_inference_steps=steps, guidance_scale=guidance, generator=generator)\n",
        "        img = out.images[0]\n",
        "        return {\"image\": img, \"metadata\": {\"prompt\": prompt, \"negative\": negative_prompt, \"height\": height, \"width\": width, \"steps\": steps, \"guidance\": guidance, \"seed\": seed}}\n",
        "\"\"\")\n",
        "\n",
        "# ---------- Agent (planner + tools + guardrails) ----------\n",
        "w(\"src/reli_core/agent/guardrails.py\", \"\"\"\n",
        "from typing import Tuple\n",
        "\n",
        "BLOCKED = [\"suicide\", \"violence\", \"illegal\", \"self-harm\", \"bioweapon\"]\n",
        "def check_safe(prompt: str) -> Tuple[bool, str]:\n",
        "    p = (prompt or \"\").lower()\n",
        "    if any(b in p for b in BLOCKED):\n",
        "        return False, \"Prompt rejected by safety policy.\"\n",
        "    return True, \"\"\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/agent/tools.py\", \"\"\"\n",
        "from typing import Dict\n",
        "from ..pipeline import process_claim\n",
        "from ..diffusion.sd_service import SDService\n",
        "\n",
        "_sd_singleton = None\n",
        "\n",
        "def projectQA(query: str) -> Dict:\n",
        "    return process_claim(query)\n",
        "\n",
        "def stableDiffusion(args: Dict) -> Dict:\n",
        "    global _sd_singleton\n",
        "    if _sd_singleton is None:\n",
        "        _sd_singleton = SDService()\n",
        "    prompt = args.get(\"prompt\",\"\")\n",
        "    neg = args.get(\"negative_prompt\")\n",
        "    h = int(args.get(\"height\",512)); w = int(args.get(\"width\",512))\n",
        "    steps = int(args.get(\"steps\",25)); guidance = float(args.get(\"guidance\",7.5))\n",
        "    seed = args.get(\"seed\")\n",
        "    out = _sd_singleton.generate(prompt=prompt, negative_prompt=neg, height=h, width=w, steps=steps, guidance=guidance, seed=seed)\n",
        "    return out\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/agent/agent.py\", \"\"\"\n",
        "from typing import Dict, Any\n",
        "from .guardrails import check_safe\n",
        "from .tools import projectQA, stableDiffusion\n",
        "\n",
        "def route_agent(prompt: str, cfg: Dict) -> Dict[str, Any]:\n",
        "    ok, msg = check_safe(prompt)\n",
        "    if not ok:\n",
        "        return {\"error\": msg, \"trace\": []}\n",
        "    allow_images = cfg.get(\"agent\",{}).get(\"allow_images\", True)\n",
        "    lower = (prompt or \"\").lower()\n",
        "    trace = []\n",
        "    if allow_images and any(k in lower for k in [\"generate an image\",\"make an image\",\"draw\",\"illustration\",\"poster\",\"infographic\",\"visualize\"]):\n",
        "        trace.append({\"tool\":\"stableDiffusion\", \"args\":{\"prompt\": prompt}})\n",
        "        img = stableDiffusion({\"prompt\": prompt})\n",
        "        return {\"type\":\"image\",\"result\": img, \"trace\": trace}\n",
        "    # default to projectQA\n",
        "    trace.append({\"tool\":\"projectQA\", \"args\":{\"query\": prompt}})\n",
        "    qa = projectQA(prompt)\n",
        "    return {\"type\":\"qa\",\"result\": qa, \"trace\": trace}\n",
        "\"\"\")\n",
        "\n",
        "# ---------- FastAPI ----------\n",
        "w(\"src/reli_core/api/main.py\", \"\"\"\n",
        "from fastapi import FastAPI\n",
        "from pydantic import BaseModel\n",
        "from typing import Optional, Dict, Any\n",
        "from ..pipeline import process_claim\n",
        "from ..config import load_run_config\n",
        "from ..agent.agent import route_agent\n",
        "from ..graph.build_graph import load_graph\n",
        "from ..graph.graphrag import graphrag_retrieve\n",
        "\n",
        "app = FastAPI(title=\"ReliScore API\")\n",
        "CFG = load_run_config()\n",
        "\n",
        "class ClaimIn(BaseModel):\n",
        "    claim: str\n",
        "\n",
        "class AgentIn(BaseModel):\n",
        "    prompt: str\n",
        "\n",
        "class GraphIn(BaseModel):\n",
        "    query: str\n",
        "\n",
        "@app.get(\"/healthz\")\n",
        "def healthz():\n",
        "    return {\"ok\": True}\n",
        "\n",
        "@app.post(\"/qa/factcheck\")\n",
        "def factcheck(inp: ClaimIn):\n",
        "    return process_claim(inp.claim)\n",
        "\n",
        "@app.post(\"/agent/route\")\n",
        "def agent_route(inp: AgentIn):\n",
        "    return route_agent(inp.prompt, CFG)\n",
        "\n",
        "@app.post(\"/qa/graphrag\")\n",
        "def graphrag_endpoint(inp: GraphIn):\n",
        "    g = load_graph()  # may be None\n",
        "    # This requires you to pass corpus items client-side; here we return only that no graph is present or not.\n",
        "    return {\"graph_loaded\": bool(g)}\n",
        "\"\"\")\n",
        "print(\"✅ Week-7 modules written.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "CTSaNdF1Mzsg",
        "outputId": "2535423a-4131-41ca-c1c0-43eea91590ce"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Week-7 modules written.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Update pipeline to include Graph-RAG + Multi-Hop hooks\n",
        "from pathlib import Path, PurePosixPath\n",
        "import textwrap\n",
        "\n",
        "PIPELINE_PATH = Path(\"src/reli_core/pipeline.py\")\n",
        "PIPELINE_PATH.write_text(textwrap.dedent(\"\"\"\n",
        "from typing import Dict, List, Tuple\n",
        "from statistics import mean\n",
        "from .safety import sanitize_claim, safety_checks\n",
        "from .nlp.claim_detect import classify_intent, query_terms\n",
        "from .nlp.normalize import normalize_title\n",
        "from .sources.pubmed import search_pubmed\n",
        "from .sources.europe_pmc import search_eupmc\n",
        "from .sources.crossref import search_crossref\n",
        "from .sources.preprints import search_preprints\n",
        "from .sources.ctgov import search_ctgov\n",
        "from .sources.fda import search_fda_oncology\n",
        "from .sources.fulltext import enrich_oa\n",
        "from .extract.effects import extract_effects, infer_direction\n",
        "from .aggregate.prevention import pooled_effect\n",
        "from .reasoner.verdict import decide_verdict\n",
        "from .ranking import rank_items\n",
        "from .graph.build_graph import build_entity_graph, persist_graph, load_graph\n",
        "from .graph.graphrag import graphrag_retrieve\n",
        "from .multihop.router import route as route_hops\n",
        "from .multihop.qa import run_multihop\n",
        "from .config import load_run_config\n",
        "\n",
        "CFG = load_run_config()\n",
        "\n",
        "def _counts(items: List[Dict]) -> Tuple[int,int,int]:\n",
        "    s = sum(1 for x in items if (x.get(\"direction\") or \"\").lower()==\"supports\")\n",
        "    r = sum(1 for x in items if (x.get(\"direction\") or \"\").lower()==\"refutes\")\n",
        "    u = len(items) - s - r\n",
        "    return s, r, max(0,u)\n",
        "\n",
        "def _year_span(items: List[Dict]):\n",
        "    years = [y for y in (x.get(\"year\") for x in items) if isinstance(y,int)]\n",
        "    return (min(years), max(years)) if years else (None, None)\n",
        "\n",
        "def _avg_score(items: List[Dict]) -> float:\n",
        "    return round(mean([x.get(\"_score\",0) for x in items]) if items else 0.0, 2)\n",
        "\n",
        "def emit_study_points(items: List[Dict]) -> List[Dict]:\n",
        "    out = []\n",
        "    for it in items:\n",
        "        it[\"title\"] = normalize_title(it.get(\"title\"))\n",
        "        eff = extract_effects(it.get(\"abstract\",\"\")) or extract_effects(it.get(\"summary\",\"\")) or extract_effects(it.get(\"title\",\"\"))\n",
        "        if eff: it[\"effect\"] = eff\n",
        "        it[\"direction\"] = infer_direction(it.get(\"title\",\"\"), it.get(\"abstract\",\"\"), it.get(\"effect\"))\n",
        "        out.append(it)\n",
        "    return out\n",
        "\n",
        "def aggregate(items: List[Dict], intent: str) -> Dict:\n",
        "    agg = {}\n",
        "    if intent == \"prevention\":\n",
        "        agg[\"prevention\"] = pooled_effect(items)\n",
        "    return agg\n",
        "\n",
        "def _top_effect_snippets(items: List[Dict], k: int = 5):\n",
        "    picks = []\n",
        "    for it in items:\n",
        "        e = it.get(\"effect\")\n",
        "        if isinstance(e, dict) and e.get(\"value\"):\n",
        "            s = {\n",
        "                \"title\": (it.get(\"title\") or \"\")[:180],\n",
        "                \"year\": it.get(\"year\"),\n",
        "                \"metric\": e.get(\"metric\"),\n",
        "                \"value\": e.get(\"value\"),\n",
        "                \"ci_low\": e.get(\"ci_low\"),\n",
        "                \"ci_high\": e.get(\"ci_high\"),\n",
        "                \"direction\": it.get(\"direction\"),\n",
        "                \"source\": it.get(\"source\"),\n",
        "                \"id\": it.get(\"id\"),\n",
        "                \"oa_url\": it.get(\"oa_url\"),\n",
        "                \"_score\": it.get(\"_score\",0),\n",
        "            }\n",
        "            picks.append(s)\n",
        "    picks.sort(key=lambda z: z.get(\"_score\",0), reverse=True)\n",
        "    return picks[:k]\n",
        "\n",
        "def build_narrative_facts(claim: str, intent: str, ranked_items: List[Dict], verdict: Dict, aggregates: Dict, hop_trace=None) -> Dict:\n",
        "    s, r, u = _counts(ranked_items)\n",
        "    y0, y1 = _year_span(ranked_items)\n",
        "    avg = _avg_score(ranked_items)\n",
        "    pooled = (aggregates or {}).get(\"prevention\", {}).get(\"pooled\")\n",
        "    facts = {\n",
        "        \"claim\": claim,\n",
        "        \"intent\": intent,\n",
        "        \"verdict\": verdict,\n",
        "        \"counts\": {\"supports\": s, \"refutes\": r, \"unclear\": u, \"total\": len(ranked_items)},\n",
        "        \"years\": {\"earliest\": y0, \"latest\": y1},\n",
        "        \"avg_score\": avg,\n",
        "        \"pooled_effect\": pooled,\n",
        "        \"top_effects\": _top_effect_snippets(ranked_items, k=6),\n",
        "        \"top_titles\": [(it.get(\"year\"), (it.get(\"title\") or \"\")[:180]) for it in ranked_items[:8]],\n",
        "        \"hop_trace\": hop_trace or [],\n",
        "    }\n",
        "    return facts\n",
        "\n",
        "def _retrieve_corpus(intent: str, q: dict) -> List[Dict]:\n",
        "    pools: List[Dict] = []\n",
        "    if intent == \"meta_news\":\n",
        "        pools += search_fda_oncology(q.get(\"fda\",\"\"), n=25)\n",
        "    pools += search_pubmed(q.get(\"pubmed\",\"\"), n=20)\n",
        "    pools += search_eupmc(q.get(\"eupmc\",\"\"), n=20)\n",
        "    pools += search_crossref(q.get(\"crossref\",\"\"), n=10)\n",
        "    pools += search_preprints(q.get(\"preprint\",\"\"), n=8)\n",
        "    pools += search_ctgov(q.get(\"ctgov\",\"\"), n=8)\n",
        "    items = [enrich_oa(x) for x in pools]\n",
        "    return items\n",
        "\n",
        "def process_claim(claim_raw: str) -> Dict:\n",
        "    claim = sanitize_claim(claim_raw)\n",
        "    sflags = safety_checks(claim)\n",
        "    intent = classify_intent(claim)\n",
        "    q = query_terms(claim, intent)\n",
        "    # Step 1: retrieve\n",
        "    corpus = _retrieve_corpus(intent, q)\n",
        "    # Step 2: effects + directions\n",
        "    study_points = emit_study_points(corpus)\n",
        "    ranked = rank_items(study_points)\n",
        "    # Build/Load Graph for Graph-RAG\n",
        "    g = load_graph()\n",
        "    if g is None:\n",
        "        try:\n",
        "            g = build_entity_graph(ranked)\n",
        "            persist_graph(g)\n",
        "        except Exception:\n",
        "            g = None\n",
        "    # Router for multi-hop\n",
        "    hop_mode = route_hops(claim)\n",
        "    hop_trace = []\n",
        "    if hop_mode == \"multi_hop\" and g is not None:\n",
        "        try:\n",
        "            mh = run_multihop(g, claim, ranked, hop_limit=CFG.get(\"multihop\",{}).get(\"hop_limit\",3), k=CFG.get(\"graphrag\",{}).get(\"retriever_k\",6))\n",
        "            hop_trace = mh.get(\"hop_trace\",[])\n",
        "            # augment ranked with any spans as pseudo-items (for visibility)\n",
        "            for sp in (mh.get(\"graph_snippets\") or [])[:5]:\n",
        "                ranked.append({\n",
        "                    \"id\": sp.get(\"source_id\",\"graph\"),\n",
        "                    \"source\": \"GraphRAG\",\n",
        "                    \"title\": sp.get(\"title\",\"\"),\n",
        "                    \"year\": sp.get(\"year\"),\n",
        "                    \"tier\": \"case_series\",\n",
        "                    \"applicability\": 0.7,\n",
        "                    \"oa_url\": sp.get(\"oa_url\",\"\"),\n",
        "                    \"abstract\": sp.get(\"text\",\"\"),\n",
        "                    \"direction\": \"unclear\",\n",
        "                    \"_score\": 1.0\n",
        "                })\n",
        "            ranked = rank_items(ranked)\n",
        "        except Exception:\n",
        "            pass\n",
        "    # Reason\n",
        "    verdict = decide_verdict(ranked, intent=intent)\n",
        "    aggregates = {\"prevention\": pooled_effect(ranked)} if intent == \"prevention\" else {}\n",
        "    facts = build_narrative_facts(claim, intent, ranked, verdict, aggregates, hop_trace=hop_trace)\n",
        "    return {\n",
        "        \"claim\": claim,\n",
        "        \"intent\": intent,\n",
        "        \"safety\": sflags,\n",
        "        \"study_points\": ranked,\n",
        "        \"aggregates\": aggregates,\n",
        "        \"verdict\": verdict,\n",
        "        \"facts\": facts,\n",
        "        \"router_debug\": {\"mode\": hop_mode}\n",
        "    }\n",
        "\"\"\").strip())\n",
        "print(\"✅ Pipeline extended with Graph-RAG + Multi-Hop hooks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjGhAa71M2Dm",
        "outputId": "c667a359-9c13-437e-9145-c6fc36089704"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Pipeline extended with Graph-RAG + Multi-Hop hooks.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Visual modules (unchanged) + insights\n",
        "from pathlib import Path, PurePosixPath\n",
        "import textwrap\n",
        "\n",
        "w = lambda p,c: Path(p).write_text(textwrap.dedent(c).strip()+\"\\n\", encoding=\"utf-8\")\n",
        "\n",
        "w(\"src/reli_core/viz.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def beeswarm_like(study_points: List[Dict]):\n",
        "    xs = [i for i,_ in enumerate(study_points)]\n",
        "    ys = [s.get(\"_score\",0) for s in study_points]\n",
        "    fig, ax = plt.subplots(figsize=(6,3))\n",
        "    ax.scatter(xs, ys, alpha=0.8)\n",
        "    ax.set_xlabel(\"Study rank\")\n",
        "    ax.set_ylabel(\"Score\")\n",
        "    ax.set_title(\"Evidence Beeswarm (score vs rank)\")\n",
        "    return fig\n",
        "\n",
        "def forest_plot(study_points: List[Dict]):\n",
        "    effs, labels = [], []\n",
        "    for s in study_points[:15]:\n",
        "        e = s.get(\"effect\")\n",
        "        if e and e.get(\"value\"):\n",
        "            effs.append((e[\"value\"], e.get(\"ci_low\"), e.get(\"ci_high\")))\n",
        "            labels.append((s.get(\"title\") or s.get(\"id\",\"\"))[:40])\n",
        "    if not effs:\n",
        "        fig, ax = plt.subplots(figsize=(6,2))\n",
        "        ax.text(0.5,0.5,\"No extractable effects\",ha=\"center\",va=\"center\"); ax.axis(\"off\")\n",
        "        return fig\n",
        "    fig, ax = plt.subplots(figsize=(7,0.4*len(effs)+1))\n",
        "    y = list(range(len(effs)))\n",
        "    vals = [v for v, lo, hi in effs]\n",
        "    los = [lo if lo else v for v, lo, hi in effs]\n",
        "    his = [hi if hi else v for v, lo, hi in effs]\n",
        "    ax.errorbar(vals, y, xerr=[[v-l for v,l in zip(vals,los)], [h-v for v,h in zip(vals,his)]], fmt='o', capsize=3)\n",
        "    ax.axvline(1.0, linestyle=\"--\")\n",
        "    ax.set_yticks(y); ax.set_yticklabels(labels); ax.set_xlabel(\"Effect ratio (RR/OR/HR)\")\n",
        "    ax.invert_yaxis(); ax.set_title(\"Forest Plot\")\n",
        "    return fig\n",
        "\n",
        "def timeline(study_points: List[Dict]):\n",
        "    pts = [(s.get(\"year\"), s.get(\"_score\",0)) for s in study_points if s.get(\"year\")]\n",
        "    pts = sorted(pts)\n",
        "    if not pts:\n",
        "        fig, ax = plt.subplots(figsize=(6,2))\n",
        "        ax.text(0.5,0.5,\"No dates available\",ha=\"center\",va=\"center\"); ax.axis(\"off\")\n",
        "        return fig\n",
        "    xs = [x for x,_ in pts]; ys = [y for _,y in pts]\n",
        "    fig, ax = plt.subplots(figsize=(6,3))\n",
        "    ax.plot(xs, ys, marker=\"o\")\n",
        "    ax.fill_between(xs, [y*0.9 for y in ys], [y*1.1 for y in ys], alpha=0.2)\n",
        "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"Score\"); ax.set_title(\"Evidence Timeline\")\n",
        "    return fig\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/viz_answer.py\", \"\"\"\n",
        "from typing import List, Dict\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D  # noqa: F401\n",
        "import math\n",
        "\n",
        "def _split_counts(study_points: List[Dict]):\n",
        "    by_src = {}\n",
        "    dir_map = {\"supports\":0, \"refutes\":0, \"unclear\":0}\n",
        "    for s in study_points:\n",
        "        src = s.get(\"source\",\"Other\") or \"Other\"\n",
        "        by_src[src] = by_src.get(src,0) + 1\n",
        "        d = (s.get(\"direction\") or \"unclear\").lower()\n",
        "        if d not in dir_map: d = \"unclear\"\n",
        "        dir_map[d] += 1\n",
        "    return by_src, dir_map\n",
        "\n",
        "def reli_graph(study_points: List[Dict]):\n",
        "    _, dir_map = _split_counts(study_points)\n",
        "    total = sum(dir_map.values()) or 1\n",
        "    parts = [dir_map.get(\"supports\",0)/total, dir_map.get(\"refutes\",0)/total, dir_map.get(\"unclear\",0)/total]\n",
        "    labels = [\"Supports\",\"Refutes\",\"Unclear\"]\n",
        "    fig, ax = plt.subplots(figsize=(7,1.8))\n",
        "    left = 0.0\n",
        "    for frac, lab in zip(parts, labels):\n",
        "        ax.barh([0], [frac], left=left)\n",
        "        if frac > 0: ax.text(left + frac/2, 0, f\"{lab} {int(frac*100)}%\", va=\"center\", ha=\"center\")\n",
        "        left += frac\n",
        "    ax.set_xlim(0,1); ax.set_yticks([])\n",
        "    ax.set_title(\"ReliGraph — Evidence Split (Stacked)\")\n",
        "    ax.set_xlabel(\"Proportion of study points\")\n",
        "    return fig\n",
        "\n",
        "def trust_compass(study_points: List[Dict]):\n",
        "    n = max(1, len(study_points))\n",
        "    supp = sum(1 for s in study_points if (s.get(\"direction\") or \"\").lower()==\"supports\")\n",
        "    consensus = supp / n\n",
        "    quality = sum(s.get(\"_score\",0) for s in study_points)/n\n",
        "    fig, ax = plt.subplots(figsize=(5,4))\n",
        "    ax.scatter([consensus],[quality], s=200)\n",
        "    ax.set_xlim(0,1); ax.set_ylim(0, max(1, quality*1.5))\n",
        "    ax.set_xlabel(\"Consensus (0..1)\"); ax.set_ylabel(\"Quality (score)\")\n",
        "    ax.set_title(\"Trust Compass\")\n",
        "    return fig\n",
        "\n",
        "def timeline_ribbon(study_points: List[Dict]):\n",
        "    pts = [(s.get(\"year\"), s.get(\"_score\",0)) for s in study_points if s.get(\"year\")]\n",
        "    pts = sorted(pts)\n",
        "    if not pts:\n",
        "        fig, ax = plt.subplots(figsize=(6,2))\n",
        "        ax.text(0.5,0.5,\"No dates available\",ha=\"center\",va=\"center\"); ax.axis(\"off\")\n",
        "        return fig\n",
        "    xs = [x for x,_ in pts]; ys = [y for _,y in pts]\n",
        "    fig, ax = plt.subplots(figsize=(6,3))\n",
        "    ax.plot(xs, ys, marker=\"o\")\n",
        "    ax.fill_between(xs, [y*0.85 for y in ys], [y*1.15 for y in ys], alpha=0.2)\n",
        "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"Score\"); ax.set_title(\"Evidence Timeline Ribbon\")\n",
        "    return fig\n",
        "\n",
        "def _safe_effect_value(s: Dict):\n",
        "    e = s.get(\"effect\")\n",
        "    if isinstance(e, dict): return e.get(\"value\")\n",
        "    return None\n",
        "\n",
        "def evidence_galaxy_3d(study_points: List[Dict]):\n",
        "    xs, ys, zs, cs = [], [], [], []\n",
        "    for s in study_points:\n",
        "        y = s.get(\"year\"); ifnot = y is None\n",
        "        if not y: continue\n",
        "        xs.append(y); ys.append(s.get(\"_score\",0))\n",
        "        eff = _safe_effect_value(s)\n",
        "        try: z = math.log(eff) if isinstance(eff,(int,float)) and eff and eff > 0 else 0.0\n",
        "        except Exception: z = 0.0\n",
        "        zs.append(z); cs.append(s.get(\"applicability\",1.0))\n",
        "    fig = plt.figure(figsize=(7,4)); ax = fig.add_subplot(111, projection='3d')\n",
        "    if not xs:\n",
        "        ax.text2D(0.5,0.5,\"No 3D points\", transform=ax.transAxes); return fig\n",
        "    ax.scatter(xs, ys, zs, s=40, alpha=0.9, c=cs)\n",
        "    ax.set_xlabel(\"Year\"); ax.set_ylabel(\"Quality (score)\"); ax.set_zlabel(\"log(effect)\")\n",
        "    ax.set_title(\"Evidence Galaxy (3D)\")\n",
        "    return fig\n",
        "\"\"\")\n",
        "\n",
        "w(\"src/reli_core/viz_insights.py\", \"\"\"\n",
        "from typing import List, Dict, Tuple, Optional\n",
        "import math\n",
        "from statistics import mean\n",
        "\n",
        "def _counts(study_points: List[Dict]) -> Dict[str,int]:\n",
        "    supp = sum(1 for s in study_points if (s.get(\"direction\") or \"\").lower()==\"supports\")\n",
        "    refu = sum(1 for s in study_points if (s.get(\"direction\") or \"\").lower()==\"refutes\")\n",
        "    uncl = len(study_points) - supp - refu\n",
        "    return {\"supports\": supp, \"refutes\": refu, \"unclear\": max(0, uncl)}\n",
        "\n",
        "def _years_and_scores(study_points: List[Dict]) -> Tuple[list, list]:\n",
        "    pts = [(s.get(\"year\"), s.get(\"_score\",0)) for s in study_points if s.get(\"year\")]\n",
        "    pts = sorted(pts)\n",
        "    if not pts: return [], []\n",
        "    xs = [x for x,_ in pts]; ys = [y for _,y in pts]\n",
        "    return xs, ys\n",
        "\n",
        "def _slope(xs: list, ys: list) -> Optional[float]:\n",
        "    n = len(xs)\n",
        "    if n < 2: return None\n",
        "    xbar = sum(xs)/n; ybar = sum(ys)/n\n",
        "    num = sum((x-xbar)*(y-ybar) for x,y in zip(xs,ys))\n",
        "    den = sum((x-xbar)**2 for x in xs) or 1e-9\n",
        "    return num/den\n",
        "\n",
        "def _effects(study_points: List[Dict]):\n",
        "    vals = []\n",
        "    for s in study_points:\n",
        "        e = s.get(\"effect\")\n",
        "        if isinstance(e, dict) and isinstance(e.get(\"value\"), (int,float)) and e[\"value\"]>0:\n",
        "            vals.append(e[\"value\"])\n",
        "    return vals\n",
        "\n",
        "def insights(study_points: List[Dict], verdict: Dict) -> Dict:\n",
        "    n = len(study_points); counts = _counts(study_points)\n",
        "    consensus = (counts[\"supports\"] / n) if n>0 else 0.0\n",
        "    xs, ys = _years_and_scores(study_points)\n",
        "    trend = _slope(xs, ys)\n",
        "    effs = _effects(study_points); has_fx = len(effs) > 0\n",
        "    if has_fx:\n",
        "        log_vals = [math.log(v) for v in effs if v>0]\n",
        "        med_log = sorted(log_vals)[len(log_vals)//2] if log_vals else 0.0\n",
        "    else:\n",
        "        med_log = 0.0\n",
        "    avg_score = mean([s.get(\"_score\",0) for s in study_points]) if n else 0.0\n",
        "    label = (verdict or {}).get(\"label\",\"Unclear\")\n",
        "    return {\"n\": n, \"supports\": counts[\"supports\"], \"refutes\": counts[\"refutes\"], \"unclear\": counts[\"unclear\"],\n",
        "            \"consensus\": consensus, \"avg_score\": avg_score, \"trend_slope\": trend, \"has_effects\": has_fx,\n",
        "            \"median_log_effect\": med_log, \"label\": label}\n",
        "\n",
        "def captions_from_insights(ins: Dict) -> Dict[str, str]:\n",
        "    if ins[\"n\"] == 0: reli_take = \"No evidence found to split.\"\n",
        "    else:\n",
        "        if ins[\"supports\"] > ins[\"refutes\"]:\n",
        "            reli_take = f\"Evidence leans supportive ({ins['supports']} vs {ins['refutes']}).\"\n",
        "        elif ins[\"refutes\"] > ins[\"supports\"]:\n",
        "            reli_take = f\"Evidence leans against the claim ({ins['refutes']} vs {ins['supports']}).\"\n",
        "        else:\n",
        "            reli_take = \"Support and refutation are balanced.\"\n",
        "    reli_why = \"A larger supportive portion raises confidence; a larger refuting portion lowers it.\"\n",
        "    reli_how = \"Segments show proportions that support, refute, or are unclear.\"\n",
        "\n",
        "    tc_take = f\"Consensus ≈ {ins['consensus']:.2f} with average quality ≈ {ins['avg_score']:.2f}.\"\n",
        "    if ins[\"label\"] == \"Supported\": tc_take += \" Studies cluster toward agreement.\"\n",
        "    elif ins[\"label\"] == \"Contradicted\": tc_take += \" Studies cluster toward disagreement.\"\n",
        "    elif ins[\"label\"] == \"Mixed\": tc_take += \" Agreement is split.\"\n",
        "\n",
        "    if ins[\"trend_slope\"] is None: tl_take = \"Not enough dated studies to assess trends.\"\n",
        "    elif ins[\"trend_slope\"] > 0.01: tl_take = \"Evidence quality trends upward over time.\"\n",
        "    elif ins[\"trend_slope\"] < -0.01: tl_take = \"Evidence quality trends downward over time.\"\n",
        "    else: tl_take = \"Evidence quality is relatively stable over time.\"\n",
        "    tl_how = \"Line shows average study score by year; band shows a simple range.\"\n",
        "    tl_why = \"Upward trends suggest growing confidence; downward trends suggest weakening support.\"\n",
        "\n",
        "    if not ins[\"has_effects\"]: eg_take = \"Few studies reported effect sizes; points may cluster near zero.\"\n",
        "    else:\n",
        "        if ins[\"median_log_effect\"] < 0: eg_take = \"Reported effects tilt toward risk reductions (ratios < 1).\"\n",
        "        elif ins[\"median_log_effect\"] > 0: eg_take = \"Reported effects tilt toward risk increases (ratios > 1).\"\n",
        "        else: eg_take = \"Reported effects cluster near no change.\"\n",
        "    eg_how = \"x=year, y=quality, z≈log(effect).\"\n",
        "    eg_why = \"Stronger departures from zero hint at stronger effects.\"\n",
        "\n",
        "    return {\n",
        "        \"reli_graph\": f\"**Takeaway:** {reli_take}\\\\n*How to read:* {reli_how}\\\\n*Why it matters:* {reli_why}\",\n",
        "        \"trust_compass\": f\"**Takeaway:** {tc_take}\\\\n*How to read:* Right = agreement, Up = quality.\\\\n*Why it matters:* Position reflects how aligned and strong the evidence is.\",\n",
        "        \"timeline_ribbon\": f\"**Takeaway:** {tl_take}\\\\n*How to read:* {tl_how}\\\\n*Why it matters:* {tl_why}\",\n",
        "        \"evidence_galaxy\": f\"**Takeaway:** {eg_take}\\\\n*How to read:* {eg_how}\\\\n*Why it matters:* {eg_why}\",\n",
        "    }\n",
        "\"\"\")\n",
        "print(\"✅ Visual modules ready.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a7ORn6x6M4r7",
        "outputId": "f70ceb9d-5d2a-4293-a93d-ef862ec4e6e6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Visual modules ready.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Streamlit app (Fact-Check + Harvest + Agent & SD Lab)\n",
        "from pathlib import Path, PurePosixPath\n",
        "import textwrap\n",
        "\n",
        "Path(\"streamlit_app.py\").write_text(textwrap.dedent(\"\"\"\n",
        "import streamlit as st\n",
        "from src.reli_core.pipeline import process_claim\n",
        "from src.reli_core.topic_harvest import harvest_topic\n",
        "from src.reli_core.viz_answer import reli_graph, trust_compass, timeline_ribbon, evidence_galaxy_3d\n",
        "from src.reli_core.templates import build_citations_markdown, build_reasons_markdown\n",
        "from src.reli_core.safety import ADVICE_DISCLAIMER\n",
        "from src.reli_core.writer.lay import write_explanation\n",
        "from src.reli_core.viz_insights import insights, captions_from_insights\n",
        "from src.reli_core.graph.build_graph import load_graph\n",
        "from src.reli_core.graph.graphrag import graphrag_retrieve\n",
        "from src.reli_core.viz_graph import draw_neighborhood\n",
        "from src.reli_core.config import load_run_config\n",
        "from src.reli_core.agent.agent import route_agent\n",
        "from src.reli_core.sources.pubmed import search_pubmed\n",
        "\n",
        "import os\n",
        "st.set_page_config(page_title=\"ReliScore — Medical Fact-Check & Evidence Explorer\", layout=\"wide\")\n",
        "st.title(\"🧭 ReliScore — Fact-Check & Harvest (+ Agent & SD)\")\n",
        "\n",
        "CFG = load_run_config()\n",
        "with st.sidebar:\n",
        "    st.header(\"Settings\")\n",
        "    use_graphrag = st.checkbox(\"Use Graph-RAG enrichment\", value=True)\n",
        "    enable_agent = st.checkbox(\"Enable Agent (Week-7)\", value=False)\n",
        "    top_k = st.slider(\"Graph-RAG top-k\", 3, 12, CFG.get(\"graphrag\",{}).get(\"retriever_k\",6))\n",
        "    hop_limit = st.slider(\"Multi-Hop limit\", 1, 5, CFG.get(\"multihop\",{}).get(\"hop_limit\",3))\n",
        "    st.caption(\"Tip: Enable Agent to route between QA and Stable Diffusion (image) tools.\")\n",
        "\n",
        "tabs = st.tabs([\"✅ Fact-Check\", \"🌐 Harvest\", \"🧪 Agent & SD Lab\"])\n",
        "\n",
        "with tabs[0]:\n",
        "    st.subheader(\"Fact-Check a Claim\")\n",
        "    claim = st.text_area(\"Enter a medical claim (cancer-focused is best):\", height=120, placeholder=\"e.g., Are there real breakthroughs in cancer treatment?\")\n",
        "    audit = st.checkbox(\"Evidence Audit Mode (show retrieval signals)\", value=False)\n",
        "    if st.button(\"Check\"):\n",
        "        if enable_agent:\n",
        "            with st.spinner(\"Agent routing...\"):\n",
        "                ag = route_agent(claim, CFG)\n",
        "            if ag.get(\"type\") == \"qa\":\n",
        "                out = ag[\"result\"]\n",
        "            else:\n",
        "                st.warning(\"Agent chose image generation; switch to the Agent & SD Lab tab to see images.\")\n",
        "                out = process_claim(claim)\n",
        "        else:\n",
        "            with st.spinner(\"Searching open-access evidence...\"):\n",
        "                out = process_claim(claim)\n",
        "\n",
        "        verdict = out[\"verdict\"]; label = verdict.get(\"label\",\"Unclear\"); conf = verdict.get(\"confidence\",0.0)\n",
        "        st.markdown(f\"## Verdict: **{label}**\")\n",
        "        st.markdown(f\"**Score:** {conf:.2f}\")\n",
        "\n",
        "        st.markdown(write_explanation(claim, out[\"verdict\"], out[\"aggregates\"], out[\"study_points\"], out[\"intent\"], facts=out.get(\"facts\")))\n",
        "        st.markdown(f\"> {ADVICE_DISCLAIMER}\")\n",
        "        st.divider()\n",
        "\n",
        "        citations_md_all = build_citations_markdown(out[\"study_points\"])\n",
        "        citations_count = len(out[\"study_points\"])\n",
        "        reasons_md = build_reasons_markdown(out[\"verdict\"])\n",
        "        reasons_count = len(out[\"verdict\"].get(\"reasons\", [])) if out.get(\"verdict\") else 0\n",
        "\n",
        "        colA, colB = st.columns(2)\n",
        "        with colA:\n",
        "            with st.expander(f\"📚 References ({citations_count}) — open-access links that informed this result\", expanded=False):\n",
        "                show_all = st.checkbox(\"Show full list (otherwise first 20)\", value=False, key=\"refs_show_all\")\n",
        "                md = build_citations_markdown(out[\"study_points\"], limit=None if show_all else 20)\n",
        "                st.markdown(md)\n",
        "                st.download_button(\"Download references (.txt)\", data=citations_md_all, file_name=\"references.txt\")\n",
        "        with colB:\n",
        "            if reasons_count > 0:\n",
        "                with st.expander(f\"🧠 Why we think so ({reasons_count}) — pivotal study signals\", expanded=False):\n",
        "                    st.markdown(reasons_md)\n",
        "                    st.download_button(\"Download reasons (.txt)\", data=reasons_md, file_name=\"reasons.txt\")\n",
        "\n",
        "        if audit:\n",
        "            st.divider()\n",
        "            st.markdown(\"### Evidence Audit\")\n",
        "            st.json({\n",
        "                \"intent\": out[\"intent\"],\n",
        "                \"aggregates\": out[\"aggregates\"],\n",
        "                \"verdict\": out[\"verdict\"],\n",
        "                \"facts\": out.get(\"facts\"),\n",
        "                \"router_debug\": out.get(\"router_debug\"),\n",
        "                \"top_studies_preview\": [\n",
        "                    {k: v for k, v in s.items() if k in (\"source\",\"year\",\"tier\",\"title\",\"oa_url\",\"_score\",\"direction\",\"effect\")}\n",
        "                    for s in out[\"study_points\"][:12]\n",
        "                ]\n",
        "            })\n",
        "\n",
        "        st.divider()\n",
        "        caps = captions_from_insights(insights(out[\"study_points\"], out[\"verdict\"]))\n",
        "        c1, c2 = st.columns(2)\n",
        "        with c1:\n",
        "            st.pyplot(reli_graph(out[\"study_points\"])); st.caption(caps[\"reli_graph\"])\n",
        "            st.pyplot(timeline_ribbon(out[\"study_points\"])); st.caption(caps[\"timeline_ribbon\"])\n",
        "        with c2:\n",
        "            st.pyplot(trust_compass(out[\"study_points\"])); st.caption(caps[\"trust_compass\"])\n",
        "            st.pyplot(evidence_galaxy_3d(out[\"study_points\"])); st.caption(caps[\"evidence_galaxy\"])\n",
        "\n",
        "        if use_graphrag:\n",
        "            st.divider()\n",
        "            st.markdown(\"### Graph Neighborhood (Week-6)\")\n",
        "            g = load_graph()\n",
        "            if g is None:\n",
        "                st.info(\"Graph not built yet — it will auto-build on first run.\")\n",
        "            try:\n",
        "                spans = graphrag_retrieve(g, claim, out[\"study_points\"], k=top_k, hops=2)\n",
        "                img_path = \"data_cache/neighborhood.png\"\n",
        "                draw_neighborhood(spans.get(\"neighborhood\",{}), img_path)\n",
        "                with st.expander(\"Show Graph Neighborhood\", expanded=False):\n",
        "                    st.image(img_path)\n",
        "            except Exception as e:\n",
        "                st.warning(f\"Graph-RAG view not available: {e}\")\n",
        "\n",
        "with tabs[1]:\n",
        "    st.subheader(\"Harvest a Topic\")\n",
        "    kw = st.text_input(\"Topic keyword (e.g., 'mammography screening breast cancer')\", \"\")\n",
        "    if st.button(\"Harvest\"):\n",
        "        with st.spinner(\"Gathering sources...\"):\n",
        "            h = harvest_topic(kw)\n",
        "        st.success(f\"Found {len(h['items'])} items\")\n",
        "        for it in h[\"items\"]:\n",
        "            with st.expander(f\"{it.get('title','Untitled')}\"):\n",
        "                st.write({\n",
        "                    \"source\": it.get(\"source\"),\n",
        "                    \"year\": it.get(\"year\"),\n",
        "                    \"tier\": it.get(\"tier\"),\n",
        "                    \"oa_url\": it.get(\"oa_url\"),\n",
        "                    \"id\": it.get(\"id\"),\n",
        "                    \"summary\": it.get(\"summary\"),\n",
        "                })\n",
        "\n",
        "with tabs[2]:\n",
        "    st.subheader(\"Agent & Stable Diffusion Lab (Week-7)\")\n",
        "    prompt = st.text_area(\"Enter a prompt. The agent will route to QA (ReliScore) or to Stable Diffusion.\", height=120)\n",
        "    if st.button(\"Run Agent\"):\n",
        "        with st.spinner(\"Agent thinking...\"):\n",
        "            res = route_agent(prompt, CFG)\n",
        "        if res.get(\"error\"):\n",
        "            st.error(res[\"error\"])\n",
        "        elif res.get(\"type\") == \"qa\":\n",
        "            out = res[\"result\"]\n",
        "            st.markdown(f\"### Agent chose: QA\")\n",
        "            st.markdown(f\"**Verdict:** {out['verdict'].get('label')}  |  **Score:** {out['verdict'].get('confidence')}\")\n",
        "            st.markdown(write_explanation(prompt, out[\"verdict\"], out[\"aggregates\"], out[\"study_points\"], out[\"intent\"], facts=out.get(\"facts\")))\n",
        "            with st.expander(\"Agent Trace\", expanded=False):\n",
        "                st.json(res.get(\"trace\"))\n",
        "        elif res.get(\"type\") == \"image\":\n",
        "            st.markdown(\"### Agent chose: Stable Diffusion\")\n",
        "            img = res[\"result\"][\"image\"]\n",
        "            meta = res[\"result\"][\"metadata\"]\n",
        "            st.image(img, caption=f\"SD output — {meta}\")\n",
        "            with st.expander(\"Agent Trace\", expanded=False):\n",
        "                st.json(res.get(\"trace\"))\n",
        "        else:\n",
        "            st.info(\"No action taken.\")\n",
        "\"\"\"))\n",
        "print(\"✅ Streamlit app updated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "b4pFHylrM7Xw",
        "outputId": "b457960f-4320-49f8-8a6d-e1e028baa77d"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Streamlit app updated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Launch FastAPI (Uvicorn) + ngrok (optional)\n",
        "import subprocess, sys, threading, time, os\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "API_PORT = 8000\n",
        "if os.environ.get(\"NGROK_AUTHTOKEN\"):\n",
        "    ngrok.set_auth_token(os.environ[\"NGROK_AUTHTOKEN\"])\n",
        "api_url = ngrok.connect(API_PORT, \"http\").public_url\n",
        "print(\"FastAPI Public URL:\", api_url)\n",
        "\n",
        "def run_api():\n",
        "    cmd = [sys.executable, \"-m\", \"uvicorn\", \"src.reli_core.api.main:app\", \"--host\", \"0.0.0.0\", \"--port\", str(API_PORT)]\n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in proc.stdout:\n",
        "        print(\"[API] \", line, end=\"\")\n",
        "\n",
        "threading.Thread(target=run_api, daemon=True).start()\n",
        "time.sleep(3)\n",
        "print(\"FastAPI starting on\", f\"http://localhost:{API_PORT}\", \"→\", api_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jReHZtyvM-aP",
        "outputId": "d951e6f8-3103-4807-9acc-638aceed4aa0"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "FastAPI Public URL: https://rosaura-expenseless-averagely.ngrok-free.dev\n",
            "FastAPI starting on http://localhost:8000 → https://rosaura-expenseless-averagely.ngrok-free.dev\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Launch Streamlit with ngrok (headless)\n",
        "import subprocess, sys, threading, time, os\n",
        "from pyngrok import ngrok\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()\n",
        "\n",
        "PORT = 8501\n",
        "if os.environ.get(\"NGROK_AUTHTOKEN\"):\n",
        "    ngrok.set_auth_token(os.environ[\"NGROK_AUTHTOKEN\"])\n",
        "public_url = ngrok.connect(PORT, \"http\").public_url\n",
        "print(\"Streamlit Public URL:\", public_url)\n",
        "\n",
        "def run_streamlit():\n",
        "    cmd = [sys.executable, \"-m\", \"streamlit\", \"run\", \"streamlit_app.py\",\n",
        "           \"--server.port\", str(PORT), \"--server.address\", \"0.0.0.0\"]\n",
        "    proc = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, text=True)\n",
        "    for line in proc.stdout:\n",
        "        print(\"[ST] \", line, end=\"\")\n",
        "\n",
        "threading.Thread(target=run_streamlit, daemon=True).start()\n",
        "time.sleep(3)\n",
        "print(\"Streamlit starting on\", f\"http://localhost:{PORT}\", \"→\", public_url)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDN2eOgPNB_J",
        "outputId": "16a2f608-598c-49e5-975a-61277ac0431f"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Streamlit Public URL: https://rosaura-expenseless-averagely.ngrok-free.dev\n",
            "[ST]  \n",
            "[ST]  Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "[ST]  \n",
            "[ST]  2025-10-23 23:23:06.004 Port 8501 is already in use\n",
            "[API]  /usr/local/lib/python3.12/dist-packages/diffusers/models/transformers/transformer_2d.py:34: FutureWarning: `Transformer2DModelOutput` is deprecated and will be removed in version 1.0.0. Importing `Transformer2DModelOutput` from `diffusers.models.transformer_2d` is deprecated and this will be removed in a future version. Please use `from diffusers.models.modeling_outputs import Transformer2DModelOutput`, instead.\n",
            "[API]    deprecate(\"Transformer2DModelOutput\", \"1.0.0\", deprecation_message)\n",
            "[API]  INFO:     Started server process [13585]\n",
            "[API]  INFO:     Waiting for application startup.\n",
            "[API]  INFO:     Application startup complete.\n",
            "[API]  ERROR:    [Errno 98] error while attempting to bind on address ('0.0.0.0', 8000): [errno 98] address already in use\n",
            "[API]  INFO:     Waiting for application shutdown.\n",
            "[API]  INFO:     Application shutdown complete.\n",
            "Streamlit starting on http://localhost:8501 → https://rosaura-expenseless-averagely.ngrok-free.dev\n"
          ]
        }
      ]
    }
  ]
}